{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# This is a `basicRaytracing` python-based example of CPU 3D ray-tracing rendering application\n",
    "## This notebook has been updated by Prof. George Papagiannakis as an introduction to CPU-based ray-tracing for Elements \n",
    "### the code is based on the book \"Ray Tracing in One Weekend\" by Peter Shirley (https://raytracing.github.io/books/RayTracingInOneWeekend.html)\n",
    "### *Copyright 2021-2022 Dr. George Papagiannakis,  papagian@csd.uoc.gr*\n",
    "*All Rights Reserved*\n",
    "### *University of Crete & Foundation for Research & Technology - Hellas (FORTH)*\n",
    "---\n",
    "This notebook is also based on parts of the C++ implementation of Raytracing in One Weekend: https://github.com/RayTracing/raytracing.github.io and the Python/numpy step-by-step tutorial: https://github.com/alfiopuglisi/raytrace_weekend_numpy/blob/master/raytrace_weekend_numpy.ipynb. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "The purpose is to create a basic example of ray-tracing, purely on CPU, resulting in creating realistic and engaging images via motivating and easy to follow coding examples. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## 1. Output an image in pure Python and PPM format\n",
    "The code below outputs a simple background image using the PPM file format based on the original `RayTracingInOneWeekend` book by P. Shirley as found [here](https://github.com/RayTracing/raytracing.github.io/tree/release). \n",
    "\n",
    "The PPM file format is a very simple file format that can be used to output an image. The code below outputs a PPM image file that is `image_width` pixels wide and `image_height` pixels high. The image is a gradient that goes from black to *red* on top right, *green* to bottom left and the combination of *red + green = yellow* on bottom right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Here is an example of the PPM file format, from *Wikipedia*:\n",
    "\n",
    "![PPM 3x2 example](RayTracing/InOneWeekend/data/PPMexample.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In the above figure, the image grid is `2x3`, thus `y` is the width *(columns)* and `x` is the height *(rows)*. The first line is the header, the second line is the pixel color data. \n",
    "\n",
    "The header is `P3` which means the colors are in ASCII, `3 2` are the width and height, and `255` is the maximum color value. \n",
    "\n",
    "The pixel color data is in the format `R G B` where `R` is the red value, `G` is the green value, and `B` is the blue value. \n",
    "\n",
    "The pixel color data is in row-major order, so the first row is: \n",
    "`255 0 0   0 255 0   0 0 255` \n",
    "and the second row is: \n",
    "`255 255 0  255 255 255  0 0 0`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# what is row-major order for storage?\n",
    "Row-major order is a method of storing or accessing multidimensional arrays in memory. In this method, the elements in each row of the array are stored in consecutive memory locations. This means that when you iterate over the array, you will first go through all the elements in the first row, from left to right, then move on to the second row, and so on.\n",
    "\n",
    "In the context of pixel data, an image can be thought of as a 2D array (or a 3D array for color images), where each element of the array represents a pixel. If the pixel data is stored in row-major order, this means that the pixels are stored or accessed row by row. The top row of pixels (row 0) is stored first, followed by the second row (row 1), and so on. Within each row, the pixels are stored from left to right.\n",
    "\n",
    "The following figure illustrates the concept of row-major order for a `w by h` image, where `w` is the width of the image and `h` is the height of the image and the pixel data is stored in row-major order. The numbers represent the order in which the pixels are stored in memory, with the first pixel at the top left and the last pixel at the bottom right. Typically we use indices like **`i` for the rows** and **`j` for the columns**, so the pixel at row `i` and column `j` is stored at position `i * w + j` in the memory (if we flatten the 2D image grid into a one-dimensional array).\n",
    "\n",
    "![image wxh example](RayTracing/InOneWeekend/data/pixel-grid.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the standard way of storing images in most image processing libraries, including Python's PIL and OpenCV. \n",
    "\n",
    "It is also the way that images are typically displayed on screen, with the first pixel at the top left and the last pixel at the bottom right. Common indices for rows are `i`, `w` or `x` for the columns are `j`, `h`, `y`:\n",
    "\n",
    "| rows (r)  | Columns (c) |\n",
    "|----------|----------|\n",
    "| e.g.2    | e.g. 3    |\n",
    "| i    | j    |\n",
    "| h    | w    |\n",
    "| x    | y    |\n",
    "\n",
    "For some weird reason, Shirle's first example uses 'j' for rows and 'i' for columns, but we will stick to the standard convention and htis is reflected in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Python script below performs the following operations according to Shirley's book:\n",
    "\n",
    "- It sets the image `image_width` *(number of columns)* and `image_height` *(number of rows)*.\n",
    "- It opens a new file `output.ppm`` to write the image data.\n",
    "- It writes the header for the PPM file format.\n",
    "- It then iterates over each pixel in the image, calculating the *red (r)* and *green (g)* components based on the pixel's position. The *blue* component *(b)* is set to 0.\n",
    "- It **converts** these *floating-point* color values to **integers** in the **range 0 to 255**.\n",
    "- Finally, it writes these color values into the file *for each pixel*.\n",
    "-\n",
    "When this script is run, it will create a file named `output.ppm`` which will contain the image data in the PPM format, producing a gradient image.\n",
    "\n",
    "The conversion of the color values to integers between 0 and 255 in the given code is a crucial step for representing colors in digital images, especially in formats like PPM (Portable Pixmap). Here's an explanation of how this conversion works:\n",
    "\n",
    "1. **Fractional Color Values**: Initially, the color values (`r`, `g`, and `b`) are calculated as fractions. These fractions represent how \"intense\" or \"bright\" the color is. A value of 0 means no intensity (black), and a value close to 1 means full intensity. For example, in the code, `r` and `g` values vary from 0 to almost 1 across the width and height of the image.\n",
    "\n",
    "2. **Scaling to 0-255 Range**: Most digital images use 8 bits per color channel, which allows for 256 different levels of intensity per channel (from 0 to 255). To convert a fractional intensity value to this range, it is multiplied by the maximum intensity level (255). However, to ensure the maximum fractional value (just below 1) maps correctly to 255, the multiplier is slightly less than 256, often chosen as 255.999. This adjustment helps in rounding off the values correctly.\n",
    "\n",
    "3. **Conversion to Integer**: \n",
    "   - After multiplication, the resulting value is in the range from 0 to 255.999.\n",
    "   - This value is then converted to an integer. In C++, the `static_cast<int>()` is used, and in Python, this is done simply by using `int()`. This step truncates (or effectively rounds down) the decimal part, resulting in an integer value in the desired range of 0 to 255.\n",
    "\n",
    "4. **Application in the Code**: \n",
    "   - In the context of the code, each pixel's color intensity for red (`r`) and green (`g`) is calculated based on its position.\n",
    "   - `r` varies horizontally, and `g` varies vertically. The blue component (`b`) is set to 0, which means there will be no blue intensity in any pixel.\n",
    "   - These values are then scaled and converted to integers, giving us the appropriate red and green color values for each pixel to be written in the PPM file.\n",
    "\n",
    "5. **Print progress indicator**:\n",
    "   - This Python code uses f-string formatting to embed the expression `image_height - j` within the string. The `end=' '` argument replaces the default newline character that `print` adds to the end of its output with a space. The `flush=True` argument ensures that the output is flushed (i.e., immediately written) to the terminal, which is the equivalent of `std::flush` in C++.\n",
    "\n",
    "By performing this conversion for each pixel, the code effectively generates the color information for an entire image, where each pixel's color is represented by a set of three integers (representing the red, green, and blue channels) in the range of 0 to 255.\n",
    "\n",
    "> As described, the image shows a gradient:\n",
    "\n",
    "- The **red component (R)** increases from *left to right*.\n",
    "- The **green component (G)** increases from *top to bottom*.\n",
    "- The **blue component (B)** is consistently zero across the image.\n",
    "\n",
    "This results in a color transition from black at the top-left corner (where both R and G are zero) to yellow at the bottom-right corner (where both R and G are at their maximum, with no blue component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Set image dimensions\n",
    "image_width = 256\n",
    "image_height = 256\n",
    "\n",
    "# Open a file to write the PPM image\n",
    "with open(\"shirleyRTinOneWeekendFirstExample.ppm\", \"w\") as file:\n",
    "    # Write PPM header\n",
    "    file.write(\"P3\\n\")\n",
    "    file.write(f\"{image_width} {image_height}\\n\")\n",
    "    file.write(\"255\\n\")\n",
    "\n",
    "    # Loop over each pixel and calculate color values\n",
    "    # In this structure, the outer loop (for j in range(image_height)) iterates over the rows of the image, \n",
    "    # and for each row, the inner loop (for i in range(image_width)) iterates over the columns. \n",
    "    # This means that all the pixels in a row are processed before moving on to the next row, \n",
    "    # which is characteristic of row-major order.\n",
    "    # This is the order in which the pixels are stored in memory, and it is the order in which the pixels are\n",
    "    # written to the file. This is important because it means that the pixels are written to the file in the same order\n",
    "    # that they are stored in memory, which is the most efficient way to write the image data to the file.\n",
    "    # \n",
    "    # iterate over the rows of the image\n",
    "    for i in range(image_height):\n",
    "        # add a progress indicator\n",
    "        print(f\"\\rScanlines remaining: {image_height - i}\", end=' ', flush=True)\n",
    "        #iterate over the columns of the image\n",
    "        for j in range(image_width):\n",
    "            r = j / (image_width - 1)\n",
    "            g = i / (image_height - 1)\n",
    "            b = 0.0\n",
    "\n",
    "            # Convert color values to integers\n",
    "            ir = int(255.999 * r)\n",
    "            ig = int(255.999 * g)\n",
    "            ib = int(255.999 * b)\n",
    "\n",
    "            # Write the pixel color values to the file\n",
    "            file.write(f\"{ir} {ig} {ib}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we show to visualize the above generated image using Python and explore the PPM file format in more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the PIL library to display the image we just created\n",
    "from PIL import Image\n",
    "\n",
    "# Load the image from a file\n",
    "image = Image.open(\"shirleyRTinOneWeekendFirstExample.ppm\")\n",
    "# Display the image\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create a PPM image using NumPy and visualize it using PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part we are **diverging from Shirley's book** in order to start optimizing the above `pure` pythonic translation of the C++ book code to a more efficient implementation using the Python Image Library (PIL) and NumPy libraries, rather than simply writing PPM files in ASCII in pure python that corresponds to the original C++ code. \n",
    "\n",
    "We are still following the book chapters and the code is based on the Python/numpy implementation of `Raytracing in One Weekend` by Peter Shirley, heavily inspired by the work of [Alfiopuglisi](https://github.com/alfiopuglisi/raytrace_weekend_numpy).\n",
    "\n",
    "PIL can take as an input a multi-dimensional [rows,cols,channels] numpy array, which is exactly what we need. To vectorize the color computation, we are going to use one of the numpy \"index tricks\", *mgrid*. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets first we create a simple method for debugging by visualising the PPM with each pixel coordinates as well as each pixel R,G,B values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_pixel_grid(img, subset):\n",
    "    \"\"\"\"\n",
    "    Visualize the pixel grid of an image by plotting a subset of the image and annotating each pixel with its coordinates and RGB values.\n",
    "    \"\"\"\n",
    "\n",
    "    # extract a small subset of the image of width and height equal to subset\n",
    "    smaller_image_array = img[0:subset,0:subset,:]\n",
    "\n",
    "    # Plotting the grid of pixels\n",
    "    fig, ax = plt.subplots(figsize=(subset, subset))\n",
    "    ax.imshow(smaller_image_array, interpolation='nearest')\n",
    "\n",
    "    # Annotating each pixel with its coordinates and RGB values\n",
    "    for x in range(smaller_image_array.shape[0]):\n",
    "        for y in range(smaller_image_array.shape[1]):\n",
    "            rgb = smaller_image_array[x, y]\n",
    "            annotation = f'({x},{y})\\n[{rgb[0]},{rgb[1]},{rgb[2]}]'\n",
    "            # Choosing text color based on the brightness of the pixel for better readability\n",
    "            text_color = 'white' if np.mean(rgb) < 128 else 'black'\n",
    "            ax.text(y, x, annotation, ha='center', va='center', fontsize=6, color=text_color)\n",
    "\n",
    "    # Setting up the grid lines to match pixel boundaries\n",
    "    ax.set_xticks(np.arange(-.5, subset, 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, subset, 1), minor=True)\n",
    "    ax.grid(which='minor', color='w', linestyle='-', linewidth=2)\n",
    "    ax.tick_params(which='minor', size=0)\n",
    "    # Hiding the major tick labels\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now start with an **1-D** NumPy *mgrid* example to generate 9 numbers from 0 to 8:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "z = np.mgrid[0:9]\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the following example, *mgrid* will give us a **2D** `2x3` grid of coordinates. The `x`array *(rows)* represents the **x-coordinates of each point on the grid**, and the `y` array *(columns)* represents the **y-coordinates of each point on the grid**.  The range 0:2 for both x and 0:3 for y specifies that the grid should cover values from 0 to 2 (inclusive), creating a 2x3 grid.\n",
    "\n",
    "In the code: \n",
    "```python\n",
    "x, y = np.mgrid[0:2,0:3], \n",
    "```\n",
    "x and y are both 2D arrays generated by the `np.mgrid` function.\n",
    "\n",
    "The np.mgrid function generates a multidimensional \"meshgrid\", which is a set of coordinate arrays for vectorized evaluations of functions over a grid. The resulting grid is a set of points in a 2D space.\n",
    "\n",
    "In this case, x represents the row indices and y represents the column indices for the grid points.\n",
    "\n",
    "So, for each point in the grid, x gives the row number and y gives the column number. The grid in this case would look like this:\n",
    "\n",
    "```python\n",
    "x = [[0, 0],\n",
    "     [1, 1],\n",
    "y = [[0, 1],\n",
    "     [0, 1],\n",
    "     [0, 1]]\n",
    "```\n",
    "\n",
    "\n",
    "an example of an equivalent `3x2` image grid is shown in Figure 1 above, based this time on `NumPy` arrays. The numbers represent the order in which the pixels are stored in memory, with the first pixel at the top left and the last pixel at the bottom right. Typically we use indices like **`i` for the rows** and **`j` for the columns**, so the pixel at row `i` and column `j` is stored at (i,j) of the multiudimensional array.):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the grid and the image are height,width instead of the opposite. This is because numpy works in `row-major` i.e. rows,columns order, and the number of rows corresponds to the image height."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we replicate the actual wikipedia PPM image as in figure 1, but using this time PIL and numpy libraries to create the image with `mgrid`. We also visualise it using matplotlib and our `visualise_pixel_grid()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# create a 2x3 grid using numpy.mgrid\n",
    "x, y = np.mgrid[0:2, 0:3]\n",
    "print('x coordinates:\\n', x)\n",
    "print('y coordinates:\\n', y)\n",
    "\n",
    "print('\\n(x,y) all pairs:')\n",
    "x_flat = x.flatten()\n",
    "y_flat = y.flatten()\n",
    "for pair in zip(x_flat, y_flat):\n",
    "    print(pair)\n",
    "\n",
    "# Create a 2D array of lists\n",
    "\"\"\"\"\n",
    "The grid is a 2D array of lists, where each element of the grid is a list of 3 elements.\n",
    "The size of the grid is determined by the shape of the x array, which is assumed to be \n",
    "a two-dimensional NumPy array.\n",
    "The outer list comprehension for _ in range(x.shape[0]) is creating a list with a length \n",
    "equal to the number of rows in x. \n",
    "Each element of this list is another list, created by the inner list comprehension for _ in range(x.shape[1]).\n",
    "The inner list comprehension is creating a list with a length equal to the number of columns in x. \n",
    "Each element of this list is an empty list [].\n",
    "So, the result is a two-dimensional list (or list of lists) where the outer list represents rows \n",
    "and the inner lists represent columns. Each element in the grid is an empty list. \n",
    "This kind of structure could be useful in a variety of contexts, such as storing complex data \n",
    "associated with each point in a grid.\n",
    "\"\"\"\n",
    "grid = [[[] for _ in range(x.shape[1])] for _ in range(x.shape[0])]\n",
    "\n",
    "# Iterate over the grid and assign an empty list of 3 elements to each position\n",
    "for i in range(x.shape[0]): #rows\n",
    "    for j in range(x.shape[1]): #columns\n",
    "        grid[i][j] = [0, 0, 0]\n",
    "\n",
    "#assign the color values to the grid\n",
    "#assign red to element at position (0,0)\n",
    "grid[0][0] = [255, 0, 0]\n",
    "#assign green to element at position (0,1)\n",
    "grid[0][1] = [0, 255, 0]\n",
    "#assign blue to element at position (0,2)\n",
    "grid[0][2] = [0, 0, 255]\n",
    "#assign yellow to element at position (1,0)\n",
    "grid[1][0] = [255, 255, 0]\n",
    "#assign white to element at position (1,1)\n",
    "grid[1][1] = [255, 255, 255]\n",
    "#assign black to element at position (1,2)\n",
    "grid[1][2] = [0, 0, 0]\n",
    "\n",
    "# Print the grid\n",
    "for row in grid:\n",
    "    print(row)\n",
    "\n",
    "# Create an image from the numpy grid array\n",
    "image = Image.fromarray(np.uint8(grid))\n",
    "# Save the image to a file\n",
    "# image.save('3x2.ppm')\n",
    "# Display the image using PIL\n",
    "display(image)\n",
    "\n",
    "#get the image array from the image\n",
    "image_array = np.array(image)\n",
    "visualize_pixel_grid(image_array,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude this section by comparing the two methods, the pure pythonic and the numpy/PIL one, and we will see that the numpy/PIL method is much faster and more efficient. Thus we are moving on to the next chapters of the book using the numpy/PIL method.\n",
    "\n",
    "We will also convert the indexes to floating point. The image is pre-allocated in order to allow numpy to work on big arrays, and instead of looping over each element, we use numpy to calculate all pixel values in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# Image\n",
    "width = 256\n",
    "height = 256\n",
    "\n",
    "# Create numpy array representing the image\n",
    "# The shape of the array will be (height, width, 3)\n",
    "# The '3' represents the RGB values\n",
    "# The dtype='uint8' means values will be unsigned integers (0 to 255)\n",
    "# The initial values are all 0, which represents black\n",
    "# The array is stored in a variable named 'img'\n",
    "# ii and jj are 2D arrays containing the rows and column indices respectively of the pixels in the image\n",
    "ii, jj = np.mgrid[:float(height), :float(width)]\n",
    "print('ii is:\\n', ii)\n",
    "print('jj is:\\n',jj)\n",
    "# Create a 3D numpy array of zeros (height, width, 3 RGB channels) that is the same size as the image\n",
    "img = np.zeros((height, width, 3), dtype='uint8')\n",
    "\n",
    "# Set the RGB values in the numpy array\n",
    "# The first line, r = jj/(width-1), is calculating the red component (r) of the color for each pixel. \n",
    "# The red component is determined by the x position of the pixel: pixels on the left (where jj is small) \n",
    "# will have a low red component, and pixels on the right (where jj is large) will have a high red component.\n",
    "# division with `width-1` is to normalize the value to be between 0 and 1\n",
    "r = jj/(width-1) # red component, increasing from left to right, as jj increases (columns)\n",
    "# similar calculation for green component\n",
    "g = ii/(height-1) #green component, increasing from top to bottom as ii increases (rows)\n",
    "b = 0.25 # blue component, constant value\n",
    "\n",
    "# Set the RGB values in the numpy 3D array array: 0=red, 1=green, 2=blue arrays\n",
    "# The first index is the row number (i.e. y coordinate)\n",
    "# The second index is the column number (i.e. x coordinate)\n",
    "# The third index is the color channel (0=red, 1=green, 2=blue)\n",
    "# The values are multiplied by 255 to convert from floating point\n",
    "#   values in the range 0.0 to 1.0 to integer values in the range 0 to 255\n",
    "img[:,:,0] = 255.299*r\n",
    "img[:,:,1] = 255.299*g\n",
    "img[:,:,2] = 255.299*b\n",
    "\n",
    "# Create an image from the numpy array\n",
    "image = Image.fromarray(img)\n",
    "# Save the image to a file\n",
    "# image.save('shirleyRTinOneWeekendFirstExampleNumpy.ppm')\n",
    "# Display the image using PIL\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pixel_grid(np.array(image),10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The vec3 class\n",
    "\n",
    "We need a basic vec3 type like the one in the C++ book. Following Python traditions, class members are not encaspsulated with getters/setters (if needed, you can always turn them into properties later, without breaking backward compatibility). We also add a few useful methods, that will allow us to use the Vec3 almost as if it was a regular numpy array.\n",
    "\n",
    "Almost all graphics programs have some class(es) for storing geometric vectors and colors. In many systems thesevectors are 4D (3D position plus a homogeneous coordinate for geometry, or RGB plus an alpha transparencycomponent for colors). For our purposes, three coordinates suffice. We’ll use the same class `vec3` for `colors,locations, directions, offsets`, whatever. Some people don’t like this because it doesn’t prevent you from doingsomething silly, like subtracting a position from a color. They have a good point, but we’re going to always take the “less code” route when not obviously wrong. \n",
    "\n",
    "However, we do declare two aliases for vec3: `point3` and `color`.\n",
    "\n",
    "Since these two types are just aliases for vec3, you won't get warnings if you pass a color to a function expecting apoint3, and nothing is stopping you from adding a point3 to a color, but it makes the code a little bit easier to readand to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vec3:\n",
    "    \"\"\"\n",
    "    A class representing a 3D vector.\n",
    "\n",
    "    Attributes:\n",
    "        x (np.ndarray): The x-component of the vector.\n",
    "        y (np.ndarray): The y-component of the vector.\n",
    "        z (np.ndarray): The z-component of the vector.\n",
    "\n",
    "    The x,y,z attributes in the Vec3 class are arrays instead of a single value\n",
    "    This allows the Vec3 class to represent a collection of 3D vectors, not just a single 3D vector. \n",
    "    This can be useful in many contexts, such as ray tracing,\n",
    "    where you often need to work with large collections of vectors at once.\n",
    "    By storing x, y, and z as arrays, each instance of Vec3 can represent multiple vectors. \n",
    "    For example, the x array could hold the x-coordinates of all vectors, the y array could hold the y-coordinates, \n",
    "    and the z array could hold the z-coordinates of all vectors in the scene. \n",
    "    This design can make it easier to perform operations on all vectors at once, \n",
    "    leveraging the power of NumPy's array operations for efficient computation.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, x=0.0, y=0.0, z=0.0):\n",
    "        self.x = x if type(x) == np.ndarray else np.array(x, dtype=np.float32)\n",
    "        self.y = y if type(y) == np.ndarray else np.array(y, dtype=np.float32)\n",
    "        self.z = z if type(z) == np.ndarray else np.array(z, dtype=np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def empty(size):\n",
    "        x = np.empty(size, dtype=np.float32)\n",
    "        y = np.empty(size, dtype=np.float32)\n",
    "        z = np.empty(size, dtype=np.float32)\n",
    "        return Vec3(x,y,z)\n",
    "\n",
    "    @staticmethod\n",
    "    def zeros(size):\n",
    "        x = np.zeros(size, dtype=np.float32)\n",
    "        y = np.zeros(size, dtype=np.float32)\n",
    "        z = np.zeros(size, dtype=np.float32)\n",
    "        return Vec3(x,y,z)\n",
    "\n",
    "    @staticmethod\n",
    "    def ones(size):\n",
    "        x = np.ones(size, dtype=np.float32)\n",
    "        y = np.ones(size, dtype=np.float32)\n",
    "        z = np.ones(size, dtype=np.float32)\n",
    "        return Vec3(x,y,z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def where(condition, v1, v2):\n",
    "        x = np.where(condition, v1.x, v2.x)\n",
    "        y = np.where(condition, v1.y, v2.y)\n",
    "        z = np.where(condition, v1.z, v2.z)\n",
    "        return Vec3(x,y,z)\n",
    "    \n",
    "    def clip(self, vmin, vmax):\n",
    "        x = np.clip(self.x, vmin, vmax)\n",
    "        y = np.clip(self.y, vmin, vmax)\n",
    "        z = np.clip(self.z, vmin, vmax)\n",
    "        return Vec3(x,y,z)\n",
    "\n",
    "    def fill(self, value):\n",
    "        self.x.fill(value)\n",
    "        self.y.fill(value)\n",
    "        self.z.fill(value)\n",
    "\n",
    "    def repeat(self, n):\n",
    "        x = np.repeat(self.x, n)\n",
    "        y = np.repeat(self.y, n)\n",
    "        z = np.repeat(self.z, n)\n",
    "        return Vec3(x,y,z)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'vec3: x:%s y:%s z:%s' % (str(self.x), str(self.y), str(self.z))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.size\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Vec3(self.x + other.x, self.y + other.y, self.z + other.z)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return Vec3(self.x - other.x, self.y - other.y, self.z - other.z)\n",
    "\n",
    "    def __neg__(self):\n",
    "        return Vec3(-self.x, -self.y, -self.z)\n",
    "\n",
    "    def __mul__(self, scalar):\n",
    "        return Vec3(self.x*scalar, self.y*scalar, self.z*scalar)\n",
    "\n",
    "    def multiply(self, other):\n",
    "        return Vec3(self.x * other.x, self.y * other.y, self.z * other.z)\n",
    "\n",
    "    def __truediv__(self, scalar):\n",
    "        return Vec3(self.x/scalar, self.y/scalar, self.z/scalar)\n",
    "    \n",
    "    def tile(self, shape):\n",
    "        '''Replicate np.tile on each component'''\n",
    "        return Vec3(np.tile(self.x, shape), np.tile(self.y, shape), np.tile(self.z, shape))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''Extract a vector subset'''\n",
    "        return Vec3(self.x[idx], self.y[idx], self.z[idx])\n",
    "    \n",
    "    def __setitem__(self, idx, other):\n",
    "        '''Set a vector subset from another vector'''\n",
    "        self.x[idx] = other.x\n",
    "        self.y[idx] = other.y\n",
    "        self.z[idx] = other.z\n",
    "\n",
    "    def join(self):\n",
    "        '''Join the three components into a single 3xN array'''\n",
    "        return np.vstack((self.x, self.y, self.z))\n",
    "    \n",
    "    def append(self, other):\n",
    "        '''Append another vector to this one.\n",
    "        Use concatenate() because cupy has no append function.\n",
    "        '''\n",
    "        self.x = np.concatenate((self.x, other.x))\n",
    "        self.y = np.concatenate((self.y, other.y))\n",
    "        self.z = np.concatenate((self.z, other.z))\n",
    "        \n",
    "\n",
    "## Aliases\n",
    "Point3 = Vec3\n",
    "Color = Vec3\n",
    "\n",
    "## Utility functions\n",
    "def unit_vector(v):\n",
    "    return v / length(v)\n",
    "\n",
    "def dot(a, b):\n",
    "    \"\"\"\n",
    "    Calculate the dot product of two vectors.\n",
    "    \"\"\"\n",
    "    return a.x*b.x + a.y*b.y + a.z*b.z\n",
    "\n",
    "def length(v):\n",
    "    \"\"\"\n",
    "    Calculate the length of a vector using the length_squared() \n",
    "    instead of calculating the square root of the sum of the squares of the components\n",
    "    \"\"\"\n",
    "    return length_squared(v)**0.5\n",
    "\n",
    "def length_squared(v):\n",
    "    \"\"\"\n",
    "    Calculate the squared length of a vector.\n",
    "    instead of calculating the square root of the sum of the squares of the components\n",
    "    we can calculate the sum of the squares of the components directly (more efficient).\n",
    "    \"\"\"\n",
    "    return v.x*v.x + v.y*v.y + v.z*v.z\n",
    "\n",
    "def cross(a, b):\n",
    "    \"\"\"\n",
    "    Calculates the cross product of two vectors.\n",
    "\n",
    "    Args:\n",
    "        a (Vec3): The first vector.\n",
    "        b (Vec3): The second vector.\n",
    "\n",
    "    Returns:\n",
    "        Vec3: The cross product of the two vectors.\n",
    "    \"\"\"\n",
    "    return Vec3(a.y*b.z - a.z*b.y,\n",
    "                -(a.x*b.z - a.z*b.x),\n",
    "                a.x*b.y - a.y*b.x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also write a quick function that can take a Vec3 object and return an Image object. Our arrays are 3xN, while the Image.fromarray() method expects Nx3, so we need to swap the axes. The function is able to take 1d or 2d arrays as an input. It will assume that 1d arrays are grayscale images, and 2d arrays are composition of 3 grayscale images in RGB order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_pil(v, width, height, scale = 255.999):\n",
    "    \"\"\"\n",
    "    Converts a numpy array to a PIL image.\n",
    "\n",
    "    Parameters:\n",
    "    v (numpy.ndarray): The input array.\n",
    "    width (int): The width of the image.\n",
    "    height (int): The height of the image.\n",
    "    scale (float, optional): The scaling factor. Defaults to 255.999.\n",
    "\n",
    "    Returns:\n",
    "    PIL.Image.Image: The converted PIL image.\n",
    "    \"\"\"\n",
    "    # joins the three components (presumably representing RGB color channels) into a single 3xN array. \n",
    "    # This array is then multiplied by scale, which could be a scalar or another array used to adjust \n",
    "    # the intensity of the colors. The result is then converted to 8-bit unsigned integer format using astype(np.uint8). \n",
    "    img = (v.join() * scale).astype(np.uint8)\n",
    "\n",
    "    # The resulting 3xN array is then reshaped into a 2D array with dimensions (height, width, 3).\n",
    "    # This is done using the swapaxes(0,1) method, which swaps the first and second axes of the array,\n",
    "    # and the reshape method, which reshapes the array into the specified dimensions.\n",
    "    if len(img.shape) == 2:\n",
    "        img_rgb = img.swapaxes(0,1).reshape(height, width, 3)\n",
    "    else:\n",
    "        img_rgb = img.reshape(height, width)\n",
    "\n",
    "    return Image.fromarray(img_rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Rays, a simple camera, and background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 The ray class\n",
    "\n",
    "A direct translation of the C++ one. We add some useful methods to get/set a ray subset and get the number of rays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\n",
    "The Ray class is used to represent a ray in 3D space.\n",
    "\"\"\"\n",
    "class Ray:\n",
    "    def __init__(self, origin, direction):\n",
    "        \"\"\"\n",
    "        Initialize a Ray object.\n",
    "\n",
    "        Parameters:\n",
    "        - origin: The origin point of the ray.\n",
    "        - direction: The direction vector of the ray.\n",
    "        \"\"\"\n",
    "        self.origin = origin\n",
    "        self.direction = direction\n",
    "        self._direction_length_squared = None\n",
    "\n",
    "    def at(self, t):\n",
    "        \"\"\"\n",
    "        Calculate the point on the ray at a given parameter t.\n",
    "\n",
    "        Parameters:\n",
    "        - t: The parameter value.\n",
    "\n",
    "        Returns:\n",
    "        - The point on the ray at parameter t.\n",
    "        \"\"\"\n",
    "        return self.origin + self.direction*t\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get a sub-ray by indexing the origin and direction vectors.\n",
    "\n",
    "        Parameters:\n",
    "        - idx: The index value.\n",
    "\n",
    "        Returns:\n",
    "        - A sub-ray with origin and direction vectors indexed by idx.\n",
    "        \"\"\"\n",
    "        return Ray(self.origin[idx], self.direction[idx])\n",
    "\n",
    "    def __setitem__(self, idx, other):\n",
    "        \"\"\"\n",
    "        Set the origin and direction vectors of a sub-ray by indexing.\n",
    "\n",
    "        Parameters:\n",
    "        - idx: The index value.\n",
    "        - other: Another Ray object.\n",
    "\n",
    "        Returns:\n",
    "        - None\n",
    "        \"\"\"\n",
    "        self.origin[idx] = other.origin\n",
    "        self.direction[idx] = other.direction\n",
    "        self._direction_length_squared = None\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Get the length of the ray.\n",
    "\n",
    "        Returns:\n",
    "        - The length of the ray.\n",
    "        \"\"\"\n",
    "        return self.origin.x.size\n",
    "\n",
    "    def direction_length_squared(self):\n",
    "        \"\"\"\n",
    "        Calculate the squared length of the direction vector.\n",
    "\n",
    "        Returns:\n",
    "        - The squared length of the direction vector.\n",
    "        \"\"\"\n",
    "        if self._direction_length_squared is None:\n",
    "            self._direction_length_squared = length_squared(self.direction)\n",
    "        return self._direction_length_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Sending Rays Into the Scene\n",
    "\n",
    "Here is our version of the ray_color function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_color(rays):\n",
    "    \"\"\"\n",
    "    Calculates the color of the rays based on their direction.\n",
    "\n",
    "    Parameters:\n",
    "    rays (Ray): The rays for which to calculate the color.\n",
    "\n",
    "    Returns:\n",
    "    Color: The calculated color of the rays.\n",
    "    \"\"\"\n",
    "    unit_direction = unit_vector(rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    return Color(1.0, 1.0, 1.0)*(1-t) + Color(0.5, 0.7, 1.0)*t\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new image and camera defintion code is basically the same as in C++. We are going to reverse the vertical direction sign, because the Python image displays put the zero at the bottom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the aspect ratio and size of the image. The aspect ratio is the ratio of the width to the height of the image. \n",
    "# Here, it's set to 16:9, which is a common aspect ratio for screens and video formats. \n",
    "# The width of the image is set to 400 pixels. The height is then calculated based on the aspect ratio and the width \n",
    "# to ensure the image maintains the correct proportions. \n",
    "# The size of the image is then printed out.\n",
    "aspect_ratio = 16.0 / 9.0\n",
    "width = 400\n",
    "height = int(width / aspect_ratio)\n",
    "print('Image size: %dx%d' % (width, height))\n",
    "\n",
    "# Defining the size of the viewport and the focal length. \n",
    "# The viewport is the area of the scene that's visible in the image. \n",
    "# Its height is set to 2.0 units, and its width is calculated based on the aspect ratio and the height. \n",
    "# The focal length, which determines how zoomed in the image appears, is set to 1.0 units.\n",
    "viewport_height = 2.0\n",
    "viewport_width = aspect_ratio * viewport_height;\n",
    "focal_length = 1.0;\n",
    "print('Viewport size: %dx%d' % (viewport_width, viewport_height))\n",
    "\n",
    "# Defining the origin, horizontal, vertical, and lower_left_corner of the viewport.\n",
    "# The origin is the starting point of the rays that will be cast into the scene.\n",
    "# The horizontal and vertical vectors represent the width and height of the viewport, respectively.\n",
    "# The lower_left_corner is the bottom-left corner of the viewport, which is used to calculate the starting point of the rays.\n",
    "origin = Point3(0, 0, 0); # our camera is at the origin\n",
    "horizontal = Vec3(viewport_width, 0, 0); # the width of the viewport, orientation of camera \n",
    "vertical = Vec3(0, -viewport_height, 0); # the height of the viewport, orientation of camera\n",
    "# The lower_left_corner is calculated by subtracting half the width and height of the viewport from the origin,\n",
    "lower_left_corner = origin - horizontal/2 - vertical/2 - Vec3(0, 0, focal_length);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image code needs to be significantly revised: u and v are calculated directly from the image coordinates, and flattened to a vector. There is no need to allocate the output image, since it is the output of the ray color calculation.\n",
    "\n",
    "Also note how u and v are enplicitly converted to 32-bit floats. This is necessary because the *float* cast in the mgrid call uses Python floats, which are usually double precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 2D array of lists\n",
    "# The grid is a 2D array of lists, where each element of the grid is a list of 3 elements.\n",
    "# ii and jj are 2D arrays containing the rows and column indices of the pixels in the image\n",
    "# The size of the grid is determined by the shape of the ii array, which is assumed to be\n",
    "# a two-dimensional NumPy array.\n",
    "ii, jj = np.mgrid[:float(height), :float(width)]\n",
    "\n",
    "# Create a 3D numpy array of zeros (height, width, 3 RGB channels) that is the same size as the image\n",
    "# The shape of the array will be (height, width, 3)\n",
    "# The '3' represents the RGB values\n",
    "# u is the horizontal component of the pixel location\n",
    "# v is the vertical component of the pixel location\n",
    "u = (jj/(width-1)).flatten().astype(np.float32)\n",
    "v = (ii/(height-1)).flatten().astype(np.float32)\n",
    "\n",
    "# all_origins is the origin of the ray for each pixel\n",
    "all_origins = origin.tile((u.size,))\n",
    "# Ray direction is calculated by adding the horizontal and vertical components to the lower_left_corner\n",
    "# and then subtracting the origin\n",
    "r = Ray(all_origins, lower_left_corner\n",
    "                     + horizontal * u\n",
    "                     + vertical * v\n",
    "                     - all_origins)\n",
    "\n",
    "# Calculate the color of the rays\n",
    "# The color of the rays is calculated using the ray_color function, which takes the rays as input and returns the color of the rays.\n",
    "img = ray_color(r)\n",
    "\n",
    "# Create an image from the numpy array\n",
    "display(convert_to_pil(img, width, height, scale = 255.299))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Adding a Sphere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sphere code is the same as in C++.\n",
    "\n",
    "We modify the ray_color() function to force the red color wherever the sphere has been hit. Instead of using an *if* instruction ray-by-ray as in C++, we use *np.where* to set all rays in one go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_sphere(center, radius, rays):\n",
    "    \"\"\"\n",
    "    Determines if a ray intersects with a sphere.\n",
    "\n",
    "    Parameters:\n",
    "    - center: The center of the sphere (tuple of x, y, z coordinates).\n",
    "    - radius: The radius of the sphere (float).\n",
    "    - rays: The ray to be tested for intersection (Ray object).\n",
    "\n",
    "    Returns:\n",
    "    - True if the ray intersects with the sphere, False otherwise.\n",
    "    \"\"\"\n",
    "    oc = rays.origin - center\n",
    "    a = dot(rays.direction, rays.direction)\n",
    "    b = 2.0 * dot(oc, rays.direction)\n",
    "    c = dot(oc, oc) - radius*radius\n",
    "    discriminant = b*b - 4*a*c\n",
    "    return discriminant > 0\n",
    "\n",
    "def ray_color(rays):\n",
    "    \"\"\"\n",
    "    Calculates the color of the rays based on their direction.\n",
    "\n",
    "    Parameters:\n",
    "    - rays: The rays to calculate the color for.\n",
    "\n",
    "    Returns:\n",
    "    - The color of the rays.\n",
    "    \"\"\"\n",
    "\n",
    "    unit_direction = unit_vector(rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    gradient = Color(1.0, 1.0, 1.0)*(1-t) + Color(0.5, 0.7, 1.0)*t\n",
    "\n",
    "    sphere = hit_sphere(Point3(0,0,-1), 0.5, rays)\n",
    "    gradient[np.where(sphere)] = Color(1, 0, 0)\n",
    "    return gradient\n",
    "\n",
    "img = ray_color(r)\n",
    "\n",
    "display(convert_to_pil(img, width, height, scale = 255.299))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Surface Normals and Multiple Objects\n",
    "### 6.1 Shading with Surface Normals\n",
    "\n",
    "The *if* instruction in the new C++ *hit_sphere* function is replaced by *np.where()*.\n",
    "Execution of this cell may result in a RuntimeWarning, because we are calling sqrt() on the whole frame, including where the discriminant is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_sphere(center, radius, rays):\n",
    "    \"\"\"\n",
    "    Calculates the intersection points between a ray and a sphere.\n",
    "\n",
    "    Parameters:\n",
    "    - center: The center coordinates of the sphere.\n",
    "    - radius: The radius of the sphere.\n",
    "    - rays: The ray object containing the origin and direction of the ray.\n",
    "\n",
    "    Returns:\n",
    "    - root: The intersection point(s) between the ray and the sphere. If no intersection occurs, -1.0 is returned.\n",
    "    \"\"\"\n",
    "    oc = rays.origin - center\n",
    "    a = dot(rays.direction, rays.direction)\n",
    "    b = 2.0 * dot(oc, rays.direction)\n",
    "    c = dot(oc, oc) - radius*radius\n",
    "    discriminant = b*b - 4*a*c\n",
    "    root = (-b - np.sqrt(discriminant) ) / (2.0*a)\n",
    "    return np.where(discriminant > 0, root, -1.0)\n",
    "\n",
    "def ray_color(rays):\n",
    "    \"\"\"\n",
    "    Calculates the color of the rays based on their direction and intersection with a sphere.\n",
    "\n",
    "    Parameters:\n",
    "    rays (Ray): The rays to calculate the color for.\n",
    "\n",
    "    Returns:\n",
    "    Color: The calculated color of the rays.\n",
    "    \"\"\"\n",
    "\n",
    "    unit_direction = unit_vector(rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    gradient = Color(1.0, 1.0, 1.0)*(1-t) + Color(0.5, 0.7, 1.0)*t\n",
    "\n",
    "    t = hit_sphere(Point3(0,0,-1), 0.5, rays)\n",
    "    N = unit_vector(rays.at(t) - Vec3(0, 0, -1))\n",
    "    c = Color(N.x + 1, N.y + 1, N.z + 1)\n",
    "\n",
    "    hit_rays = np.where(t > 0)\n",
    "    gradient[hit_rays] = c[hit_rays] * 0.5\n",
    "    return gradient\n",
    "\n",
    "# Replicate here the relevant part of the main code (just for display)\n",
    "img = ray_color(r)\n",
    "display(convert_to_pil(img, width, height, scale = 255.299))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to remove further warnings regarding NaNs and negative sqrt values with this setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.seterr(invalid='ignore')   # Returns the old settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Simplifying the Ray-Sphere Intersection Code\n",
    "\n",
    "The simplification is straightforward to replicate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hit_sphere(center, radius, rays):\n",
    "    \"\"\"\n",
    "    Determines if a ray intersects with a sphere.\n",
    "\n",
    "    Parameters:\n",
    "    - center: The center of the sphere.\n",
    "    - radius: The radius of the sphere.\n",
    "    - rays: The ray to be tested for intersection.\n",
    "\n",
    "    Returns:\n",
    "    - root: The parameter value at which the ray intersects with the sphere, or -1.0 if there is no intersection.\n",
    "    \"\"\"\n",
    "    oc = rays.origin - center\n",
    "    a = length_squared(rays.direction)\n",
    "    half_b = dot(oc, rays.direction)\n",
    "    c = length_squared(oc) - radius*radius\n",
    "    discriminant = half_b*half_b - a*c\n",
    "    root = (-half_b - np.sqrt(discriminant) ) / a\n",
    "    return np.where(discriminant > 0, root, -1.0)\n",
    "\n",
    "\n",
    "# Replicate here the relevant part of the main code (just for display)\n",
    "\n",
    "img = ray_color(r)\n",
    "display(convert_to_pil(img, width, height, scale = 255.299))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermezzo: benchmarking\n",
    "\n",
    "It's time to see if our efforts to keep things vectorized work. Since the original image was quite small, lets make it bigger (2000 pixels width) for benchmarking purposes, otherwise the code will finish in a few milliseconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager for Timer synchronization\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    \"\"\"\n",
    "    A context manager for measuring elapsed time.\n",
    "\n",
    "    Usage:\n",
    "    with Timer():\n",
    "        # Code to be timed\n",
    "\n",
    "    The elapsed time will be printed when the context is exited.\n",
    "    \"\"\"\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.t0 = time.time()\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        t1 = time.time()\n",
    "        print('Elapsed time: %.3f s' % (t1 - self.t0))\n",
    "\n",
    "    \n",
    "def render_image(width, height):\n",
    "    \"\"\"\n",
    "    Renders an image using ray tracing technique.\n",
    "\n",
    "    Args:\n",
    "        width (int): The width of the image.\n",
    "        height (int): The height of the image.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: The rendered image.\n",
    "    \"\"\"\n",
    "\n",
    "    with Timer():\n",
    "        ii, jj = np.mgrid[:float(height), :float(width)]\n",
    "\n",
    "        u = (jj/(width-1)).flatten().astype(np.float32)\n",
    "        v = (ii/(height-1)).flatten().astype(np.float32)\n",
    "\n",
    "        all_origins = origin.tile((u.size,))\n",
    "        r = Ray(all_origins, lower_left_corner\n",
    "                             + horizontal * u\n",
    "                             + vertical * v\n",
    "                             - all_origins)\n",
    "\n",
    "        img = ray_color(r)\n",
    "        \n",
    "    return img\n",
    "\n",
    "def render(width, height):\n",
    "    # Render the image\n",
    "    # The render_image function is called with the width and height of the image as arguments.\n",
    "    colors = render_image(width, height)\n",
    "    image = convert_to_pil(colors, width, height)\n",
    "    return image\n",
    "\n",
    "def benchmark(benchmark_width = 2000):\n",
    "    \"\"\"\n",
    "    Function to perform benchmarking of ray tracing.\n",
    "\n",
    "    Parameters:\n",
    "    - benchmark_width (int): The width of the benchmark image (default: 2000)\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    benchmark_height = int(benchmark_width / aspect_ratio)\n",
    "    print('Image size: %dx%d' % (benchmark_width, benchmark_height))\n",
    "\n",
    "    for n in range(4):\n",
    "        image = render(benchmark_width, benchmark_height)\n",
    "    #image.save('img-timer.ppm')\n",
    "    display(image)   \n",
    "benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 An Abstraction for Hittable Objects\n",
    "\n",
    "The gist of the code: hit all rays on all spheres and, for each ray, remember the closest hit. Instead of looping over rays and then on all hittable objects for each ray, we are going to loop over hittable objects and, for each object, do all the rays in one go. For any hit, we check whether we are the closest hit and update a hit_record that is kept between calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from abc import abstractmethod\n",
    "\n",
    "class HitRecord:\n",
    "    \"\"\"\n",
    "    Represents a record of a ray-object intersection.\n",
    "\n",
    "    Attributes:\n",
    "        p (Vec3): The intersection point.\n",
    "        normal (Vec3): The surface normal at the intersection point.\n",
    "        t (np.ndarray): The parameter values of the intersection.\n",
    "        front_face (np.ndarray): Indicates whether the ray hit the front face of the object.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, size):\n",
    "        self.p = Vec3.empty(size)\n",
    "        self.normal = Vec3.empty(size)\n",
    "        self.t = np.full(size, np.inf, dtype=np.float32)\n",
    "        self.front_face = np.zeros(size, dtype=np.float32)\n",
    "        \n",
    "                           \n",
    "class Hittable:\n",
    "    \"\"\"\n",
    "    Abstract base class for objects that can be hit by rays in a ray tracing simulation.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def update_hit_record(rays, t_min, t_max, hit_record: HitRecord):\n",
    "        pass\n",
    "\n",
    "    \n",
    "class Sphere(Hittable):\n",
    "    \"\"\"\n",
    "    A class representing a sphere in a ray tracing scene.\n",
    "\n",
    "    Attributes:\n",
    "    - center: The center point of the sphere.\n",
    "    - radius: The radius of the sphere.\n",
    "\n",
    "    Methods:\n",
    "    - update_hit_record(rays, t_min, t_max, hit_record): Updates the hit record with information about the intersection between the rays and the sphere.\n",
    "    \"\"\"\n",
    "    def __init__(self, center, radius):\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "\n",
    "    def update_hit_record(self, rays, t_min, t_max, hit_record):\n",
    "        \"\"\"\n",
    "        Updates the hit record with information about the intersection between the rays and the sphere.\n",
    "\n",
    "        Parameters:\n",
    "        - rays: The rays to be tested for intersection.\n",
    "        - t_min: The minimum value of t for a valid intersection.\n",
    "        - t_max: The maximum value of t for a valid intersection.\n",
    "        - hit_record: The hit record to be updated with the intersection information.\n",
    "        \"\"\"\n",
    "        oc = rays.origin - self.center\n",
    "        a = length_squared(rays.direction)\n",
    "        half_b = dot(oc, rays.direction)\n",
    "        c = length_squared(oc) - self.radius*self.radius\n",
    "        discriminant = half_b*half_b - a*c\n",
    "        \n",
    "        root = np.sqrt(discriminant)\n",
    "        t1 = (-half_b - root) / a\n",
    "        t2 = (-half_b + root) / a\n",
    "        hit1 = np.logical_and(t1 < t_max, t1 > t_min)\n",
    "        hit2 = np.logical_and(t2 < t_max, t2 > t_min)\n",
    "        \n",
    "        # Combine the two hits, precedence to t1 (closest)\n",
    "        t = np.where(hit2, t2, np.inf)\n",
    "        t = np.where(hit1, t1, t)       \n",
    "        \n",
    "        # Detect where in the rays list we are the closest hit\n",
    "        closest = np.where(t < hit_record.t)\n",
    "        \n",
    "        # Calculate normal\n",
    "        hit_rays = rays[closest]\n",
    "        \n",
    "        p = hit_rays.at(t[closest])\n",
    "        outward_normal = (p - self.center) / self.radius \n",
    "        front_face = dot(hit_rays.direction, outward_normal) < 0 \n",
    "        normal = Vec3.where(front_face, outward_normal, -outward_normal)\n",
    "        \n",
    "        # Update hit records\n",
    "        hit_record.p[closest] = p\n",
    "        hit_record.normal[closest] = normal\n",
    "        hit_record.t[closest] = t[closest]\n",
    "        hit_record.front_face[closest] = front_face\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not really a need for the hittable_list type. Rather, we can just loop over the world in three lines. Whenever we didn't hit anything in the world, *hit_record.t* will be infinite, and we put the gradient there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a world with two spheres\n",
    "# The world is a list of hittable objects, in this case, two spheres.\n",
    "# The first sphere is centered at (0,0,-1) with a radius of 0.5, \n",
    "# and the second sphere (ground) is centered at (0,-100.5,-1) with a radius of 100 (large enough to represent the ground)\n",
    "world = [\n",
    "    Sphere(Point3(0,0,-1), 0.5),\n",
    "    Sphere(Point3(0,-100.5,-1), 100),\n",
    "]\n",
    "\n",
    "# here we extend the previous ray_color function to take into account the hit_record\n",
    "def ray_color(rays):\n",
    "\n",
    "    unit_direction = unit_vector(rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    gradient = Color(1.0, 1.0, 1.0)*(1-t) + Color(0.5, 0.7, 1.0)*t\n",
    "\n",
    "    hit_record = HitRecord(len(rays))\n",
    "    for hittable in world:\n",
    "        hittable.update_hit_record(rays, 0, np.inf, hit_record)\n",
    "\n",
    "    hits = np.where(hit_record.t != np.inf)\n",
    "    hit_color = (hit_record.normal[hits] + Vec3(1,1,1)) * 0.5\n",
    "    gradient[hits] = hit_color\n",
    "    return gradient\n",
    "\n",
    "img = ray_color(r)\n",
    "display(convert_to_pil(img, width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermezzo: new benchmark\n",
    "A bit slower but not by much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Antialiasing\n",
    "### 7.1 Some Random Number Utilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.uniform(low=0.0, high=1.0, size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will wrap the to have a cast to float 32bits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_random(low, high, size):\n",
    "    return np.random.uniform(low, high, size).astype(np.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Generating Pixels with Multiple Samples\n",
    "\n",
    "The `Camera` class just wraps the previous code into a single class definition. \n",
    "\n",
    "We also add a small *get_camera()* function, that will be useful later on when we will change the camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera:\n",
    "    \"\"\"\n",
    "    Represents a camera used for ray tracing.\n",
    "\n",
    "    Attributes:\n",
    "        origin (Point3): The origin point of the camera.\n",
    "        horizontal (Vec3): The horizontal vector of the camera.\n",
    "        vertical (Vec3): The vertical vector of the camera.\n",
    "        lower_left_corner (Vec3): The lower left corner of the camera's viewport.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        aspect_ratio = 16.0 / 9.0;\n",
    "        viewport_height = 2.0;\n",
    "        viewport_width = aspect_ratio * viewport_height;\n",
    "        focal_length = 1.0;\n",
    "\n",
    "        self.origin = Point3(0, 0, 0);\n",
    "        self.horizontal = Vec3(viewport_width, 0.0, 0.0);\n",
    "        self.vertical = Vec3(0.0, -viewport_height, 0.0);\n",
    "        self.lower_left_corner = (self.origin\n",
    "                                  - self.horizontal/2\n",
    "                                  - self.vertical/2\n",
    "                                  - Vec3(0, 0, focal_length))\n",
    "\n",
    "    def get_ray(self, u, v):\n",
    "        all_origins = origin.tile((u.size,))\n",
    "        return Ray(all_origins, self.lower_left_corner\n",
    "                                + self.horizontal * u\n",
    "                                + self.vertical * v\n",
    "                                - all_origins)\n",
    "\n",
    "\n",
    "def get_camera():\n",
    "    return Camera()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Antialiasing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add the samples per pixels as in the C++ book code of Chapter 8 for simplified antialiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratio = 16.0 / 9.0\n",
    "width = 400\n",
    "height = int(width / aspect_ratio)\n",
    "samples_per_pixel = 10    # Use just 10 values otherwise the notebook gets slow (ofcourse this highly depends on your CPU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And modify the render_image function to add the random distribution, add the generated images together and clip the output as in the C++ code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update the render_image function to use the Camera class\n",
    "def render_image(width, height):\n",
    "    with Timer():\n",
    "        ii, jj = np.mgrid[:float(height), :float(width)]\n",
    "\n",
    "        u = (jj/(width-1)).flatten().astype(np.float32)\n",
    "        v = (ii/(height-1)).flatten().astype(np.float32)\n",
    "\n",
    "        cam = get_camera()\n",
    "\n",
    "        img = Vec3.zeros(width * height)\n",
    "        for s in range(samples_per_pixel):\n",
    "\n",
    "            uu = u + my_random(0.0, 1.0, u.size) / (width - 1)\n",
    "            vv = v + my_random(0.0, 1.0, v.size) / (height - 1)\n",
    "\n",
    "            r = cam.get_ray(uu,vv)\n",
    "\n",
    "            img += ray_color(r)\n",
    "\n",
    "        # Divide the color by the number of samples for antialiasing\n",
    "        img *= 1.0 / samples_per_pixel\n",
    "        return img.clip(0.0, 0.999)\n",
    "\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Diffuse Materials\n",
    "### 9.1 A Simple Diffuse Material\n",
    "\n",
    "The C++ code uses recursion, which makes sense since it is working on single rays that are bouncing around. We are instead working with numpy arrays, so we have refactored the code into an interation based on depth.\n",
    "\n",
    "At each iteration, the number of rays bouncing around is reduced, and so is the hit record table. The `HitRecord.index` array keeps track of where in the image the rays where originally going, so we can use their last bounce to generate the image.\n",
    "\n",
    "This requires a major refactor of the ray_color() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratio = 16.0 / 9.0\n",
    "width = 400\n",
    "height = int(width / aspect_ratio)\n",
    "samples_per_pixel = 10    # Use just 10 values otherwise the notebook gets too slow\n",
    "max_depth = 50\n",
    "\n",
    "class HitRecord:\n",
    "    def __init__(self, n, empty=False):\n",
    "        self.p           = empty or Vec3.empty(n)\n",
    "        self.normal      = empty or Vec3.empty(n)\n",
    "        self.t           = empty or np.full(n, np.inf, dtype=np.float32)\n",
    "        self.front_face  = empty or np.zeros(n, dtype=np.float32)\n",
    "        self.index       = empty or np.arange(n, dtype=np.int32)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        other = HitRecord(len(idx), empty=True)\n",
    "        other.p          = self.p[idx]\n",
    "        other.normal     = self.normal[idx]\n",
    "        other.t          = self.t[idx]\n",
    "        other.front_face = self.front_face[idx]\n",
    "        other.index      = self.index[idx]\n",
    "        return other\n",
    "    \n",
    "    \n",
    "def random_in_unit_sphere(n):\n",
    "    '''Generate random Vec3 arrays in batches and keep the ones inside the unit sphere'''\n",
    "\n",
    "    values = Vec3.zeros(0)\n",
    "\n",
    "    while len(values) < n:\n",
    "        random_values = Vec3(my_random(-1.0, 1.0, n), my_random(-1.0, 1.0, n), my_random(-1.0, 1.0, n))\n",
    "        good_ones = length_squared(random_values) < 1\n",
    "        values.append(random_values[good_ones])\n",
    "        \n",
    "    return values[np.arange(n)]\n",
    "\n",
    "\n",
    "def ray_color(rays):\n",
    "    '''Iterative version of ray_color'''\n",
    "\n",
    "    frame_intensity = np.full(len(rays), 1.0, dtype=np.float32)\n",
    "    frame_rays = rays\n",
    "    hit_record = HitRecord(len(rays))\n",
    "\n",
    "    for d in range(max_depth):\n",
    "\n",
    "        # Initialize all distances to infinite\n",
    "        hit_record.t.fill(np.inf)\n",
    "        for hittable in world:\n",
    "            hittable.update_hit_record(rays, 0, np.inf, hit_record)\n",
    "\n",
    "        # Rays that have hit something will be used in the next iteration\n",
    "        hit_idx = np.where(hit_record.t != np.inf)[0]\n",
    "\n",
    "        if len(hit_idx) > 0:\n",
    "\n",
    "            # Narrow down the hit record and calculate new rays\n",
    "            hit_record = hit_record[hit_idx]\n",
    "            \n",
    "            target = (hit_record.p\n",
    "                      + hit_record.normal\n",
    "                      + random_in_unit_sphere(len(hit_idx)))\n",
    "\n",
    "            rays = Ray(hit_record.p, target - hit_record.p)\n",
    "\n",
    "            # Update global arrays\n",
    "            frame_rays.direction[hit_record.index] = rays.direction\n",
    "            frame_intensity[hit_record.index] *= 0.5 \n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    unit_direction = unit_vector(frame_rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    img = (Color(1.0, 1.0, 1.0) * (1 - t) + Color(0.5, 0.7, 1.0) * t) * frame_intensity\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Using Gamma Correction for Accurate Color Intensity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gamma correction goes into our get_image() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# refactor the render_image function to use gamma correction\n",
    "def render_image(width, height):\n",
    "    with Timer():\n",
    "        ii, jj = np.mgrid[:float(height), :float(width)]\n",
    "\n",
    "        u = (jj/(width-1)).flatten().astype(np.float32)\n",
    "        v = (ii/(height-1)).flatten().astype(np.float32)\n",
    "\n",
    "        cam = get_camera()\n",
    "\n",
    "        img = Vec3.zeros(width * height)\n",
    "        for s in range(samples_per_pixel):\n",
    "\n",
    "            uu = u + my_random(0.0, 1.0, u.size) / (width - 1)\n",
    "            vv = v + my_random(0.0, 1.0, v.size) / (height - 1)\n",
    "\n",
    "            r = cam.get_ray(uu,vv)\n",
    "\n",
    "            img += ray_color(r)\n",
    "\n",
    "        img *=  1.0 / samples_per_pixel\n",
    "        img.x = np.sqrt(img.x)\n",
    "        img.y = np.sqrt(img.y)\n",
    "        img.z = np.sqrt(img.z)\n",
    "        img = img.clip(0.0, 0.999)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Fixing shadow acne\n",
    "We change the t_min  from 0 to 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ray_color(rays):\n",
    "    '''Iterative version of ray_color'''\n",
    "\n",
    "    frame_intensity = np.full(len(rays), 1.0, dtype=np.float32)\n",
    "    frame_rays = rays\n",
    "    hit_record = HitRecord(len(rays))\n",
    "\n",
    "    for d in range(max_depth):\n",
    "\n",
    "        # Initialize all distances to infinite and propagate all rays\n",
    "        hit_record.t.fill(np.inf)\n",
    "        for hittable in world:\n",
    "            hittable.update_hit_record(rays, 0.001, np.inf, hit_record)   # Changed here\n",
    "\n",
    "        # Rays that have hit something will be used in the next iteration\n",
    "        hit_idx = np.where(hit_record.t != np.inf)[0]\n",
    "\n",
    "        if len(hit_idx) > 0:\n",
    "\n",
    "            # Narrow down the hit record and calculate new rays\n",
    "            hit_record = hit_record[hit_idx]\n",
    "            \n",
    "            target = (hit_record.p\n",
    "                      + hit_record.normal\n",
    "                      + random_in_unit_sphere(len(hit_idx)))\n",
    "\n",
    "            rays = Ray(hit_record.p, target - hit_record.p)\n",
    "\n",
    "            # Update global arrays\n",
    "            frame_rays.direction[hit_record.index] = rays.direction\n",
    "            frame_intensity[hit_record.index] *= 0.5 \n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    unit_direction = unit_vector(frame_rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    img = (Color(1.0, 1.0, 1.0) * (1 - t) + Color(0.5, 0.7, 1.0) * t) * frame_intensity\n",
    "\n",
    "    return img\n",
    "\n",
    "display(render(width, height))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.4 True Lambertian Reflection\n",
    "We follow the C++ code of Chpater 9, changing the random_unit_vector() function to generate N arrays in one call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_unit_vectors(n):\n",
    "    a = my_random(0.0, 2.0*np.pi, n)\n",
    "    z = my_random(-1.0, 1.0, n)\n",
    "    r = np.sqrt(1 - z*z)\n",
    "    return Vec3(r*np.cos(a), r*np.sin(a), z)\n",
    "\n",
    "def ray_color(rays):\n",
    "    '''Iterative version of ray_color'''\n",
    "\n",
    "    frame_intensity = np.full(len(rays), 1.0, dtype=np.float32)\n",
    "    frame_rays = rays\n",
    "    hit_record = HitRecord(len(rays))\n",
    "\n",
    "    for d in range(max_depth):\n",
    "\n",
    "        # Initialize all distances to infinite and propagate all rays\n",
    "        hit_record.t.fill(np.inf)\n",
    "        for hittable in world:\n",
    "            hittable.update_hit_record(rays, 0.001, np.inf, hit_record) \n",
    "\n",
    "        # Rays that have hit something will be used in the next iteration\n",
    "        hit_idx = np.where(hit_record.t != np.inf)[0]\n",
    "\n",
    "        if len(hit_idx) > 0:\n",
    "\n",
    "            # Narrow down the hit record and calculate new rays\n",
    "            hit_record = hit_record[hit_idx]\n",
    "            \n",
    "            target = (hit_record.p\n",
    "                      + hit_record.normal\n",
    "                      + random_unit_vectors(len(hit_idx)))     # Changed here\n",
    "\n",
    "            rays = Ray(hit_record.p, target - hit_record.p)\n",
    "\n",
    "            # Update global arrays\n",
    "            frame_rays.direction[hit_record.index] = rays.direction\n",
    "            frame_intensity[hit_record.index] *= 0.5 \n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    unit_direction = unit_vector(frame_rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    img = (Color(1.0, 1.0, 1.0) * (1 - t) + Color(0.5, 0.7, 1.0) * t) * frame_intensity\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Metal\n",
    "### 10.2 A Data Structure to Describe Ray-Object Intersections\n",
    "\n",
    "We now have a Material abstract class and a material field in the HitRecord, updated by the Sphere field whenever there is a hit. We add just two lines to the Sphere class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "ScatterResult = namedtuple('ScatterResult', 'attenuation rays is_scattered')\n",
    "\n",
    "class Material:\n",
    "    def scatter(r_in: Ray, ray_idx, rec: HitRecord) -> ScatterResult:\n",
    "        pass\n",
    "\n",
    "class HitRecord:\n",
    "    def __init__(self, n, empty=False):\n",
    "        self.p           = empty or Vec3.empty(n)\n",
    "        self.normal      = empty or Vec3.empty(n)\n",
    "        self.t           = empty or np.full(n, np.inf, dtype=np.float32)\n",
    "        self.front_face  = empty or np.zeros(n, dtype=np.float32)\n",
    "        self.index       = empty or np.arange(n, dtype=np.int32)\n",
    "        self.material_id = empty or np.zeros(n, dtype=np.int64)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        other = HitRecord(len(idx), empty=True)\n",
    "        other.p           = self.p[idx]\n",
    "        other.normal      = self.normal[idx]\n",
    "        other.t           = self.t[idx]\n",
    "        other.front_face  = self.front_face[idx]\n",
    "        other.index       = self.index[idx]\n",
    "        other.material_id = self.material_id[idx]\n",
    "        return other\n",
    "\n",
    "\n",
    "class Sphere(Hittable):\n",
    "    '''A hittable sphere that knows how to update the hit record'''\n",
    "\n",
    "    def __init__(self, center, radius, material):\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "        self.material = material                 # Changed here\n",
    "\n",
    "    def update_hit_record(self, rays, t_min, t_max, hit_record):\n",
    "\n",
    "        oc = rays.origin - self.center\n",
    "        a = length_squared(rays.direction)\n",
    "        half_b = dot(oc, rays.direction)\n",
    "        c = length_squared(oc) - self.radius*self.radius\n",
    "        discriminant = half_b*half_b - a*c\n",
    "        \n",
    "        root = np.sqrt(discriminant)\n",
    "        t1 = (-half_b - root) / a\n",
    "        t2 = (-half_b + root) / a\n",
    "        hit1 = np.logical_and(t1 < t_max, t1 > t_min)\n",
    "        hit2 = np.logical_and(t2 < t_max, t2 > t_min)\n",
    "        \n",
    "        # Combine the two hits, precedence to t1 (closest)\n",
    "        t = np.where(hit2, t2, np.inf)\n",
    "        t = np.where(hit1, t1, t)       \n",
    "        \n",
    "        # Detect where in the rays list we are the closest hit\n",
    "        closest = np.where(t < hit_record.t)\n",
    "        \n",
    "        # Early exit if nothing hit\n",
    "        if len(closest[0]) == 0:\n",
    "            return\n",
    "        \n",
    "        # Calculate normal\n",
    "        hit_rays = rays[closest]\n",
    "        \n",
    "        p = hit_rays.at(t[closest])\n",
    "        outward_normal = (p - self.center) / self.radius \n",
    "        front_face = dot(hit_rays.direction, outward_normal) < 0 \n",
    "        normal = Vec3.where(front_face, outward_normal, -outward_normal)\n",
    "        \n",
    "        # Update hit record\n",
    "        hit_record.p[closest] = p\n",
    "        hit_record.normal[closest] = normal\n",
    "        hit_record.t[closest] = t[closest]\n",
    "        hit_record.front_face[closest] = front_face\n",
    "        hit_record.material_id[closest] = id(self.material)                 # Changed here\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.3 Modeling Light Scatter and Reflectance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lambertian(Material):\n",
    "    \n",
    "    def __init__(self, albedo: Color):\n",
    "        self.albedo = albedo\n",
    "    \n",
    "    def scatter(self, r_in: Ray, rec: HitRecord) -> ScatterResult:\n",
    "\n",
    "        scatter_direction = rec.normal + random_unit_vectors(len(r_in))\n",
    "        scattered = Ray(rec.p, scatter_direction)\n",
    "        \n",
    "        return ScatterResult(attenuation = self.albedo,\n",
    "                             rays = scattered,\n",
    "                             is_scattered = np.full(len(r_in), True, dtype=bool))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.4 Mirrored Light Reflection\n",
    "Adding the Metal class, and rewriting ray_color() to use the new materials. Since we cannot call the material subroutine pixel-by-pixel, we'll calculate all possible materials for all rays in a given iteration, and select among those to update the rays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect(v, n):\n",
    "    return v - n*2*dot(v, n)\n",
    "\n",
    "class Metal(Material):\n",
    "\n",
    "    def __init__(self, albedo: Color):\n",
    "        self.albedo = albedo\n",
    "        \n",
    "    def scatter(self, r_in: Ray, rec: HitRecord) -> ScatterResult:\n",
    "\n",
    "        reflected = reflect(unit_vector(r_in.direction), rec.normal)\n",
    "        scattered = Ray(rec.p, reflected);\n",
    "\n",
    "        return ScatterResult(attenuation = self.albedo,\n",
    "                             rays = scattered,\n",
    "                             is_scattered = dot(scattered.direction, rec.normal) > 0)  \n",
    "\n",
    "\n",
    "def ray_color(rays):\n",
    "    '''Iterative version with materials'''\n",
    "\n",
    "    frame_intensity = Vec3.ones(len(rays))\n",
    "    frame_rays = rays\n",
    "    hit_record = HitRecord(len(rays))\n",
    "\n",
    "    materials = set([x.material for x in world])\n",
    "\n",
    "    for d in range(max_depth):\n",
    "\n",
    "        # Initialize all distances to infinite and propagate all rays\n",
    "        hit_record.t.fill(np.inf)\n",
    "        hit_record.material_id.fill(0)\n",
    "        for hittable in world:\n",
    "            hittable.update_hit_record(rays, 0.001, np.inf, hit_record)         \n",
    "            \n",
    "        for material in materials:\n",
    "\n",
    "            material_hits = np.where(hit_record.material_id == id(material))[0]\n",
    "            if len(material_hits) == 0:\n",
    "                continue\n",
    "\n",
    "            my_rays = rays[material_hits]\n",
    "            my_rec = hit_record[material_hits]\n",
    "            result = material.scatter(my_rays, my_rec)         \n",
    "            \n",
    "            # All rays have done something\n",
    "            rays[material_hits] = result.rays\n",
    "            frame_rays.direction[my_rec.index] = result.rays.direction\n",
    "                \n",
    "            intensity = result.attenuation.multiply(frame_intensity[my_rec.index])\n",
    "            intensity[np.where(~result.is_scattered)] = Vec3(0,0,0)\n",
    "\n",
    "            frame_intensity[my_rec.index] = intensity\n",
    "\n",
    "            # Those that have been scattered stop here\n",
    "            not_scattered_material_idx = material_hits[~result.is_scattered]\n",
    "            hit_record.t[not_scattered_material_idx] = np.inf\n",
    "            \n",
    "        # Iterate with those rays that have been scattered by something\n",
    "        scattered_rays = np.where(hit_record.t != np.inf)[0]\n",
    "        rays = rays[scattered_rays]\n",
    "        hit_record = hit_record[scattered_rays]\n",
    "\n",
    "        if len(rays) == 0:\n",
    "            break\n",
    "            \n",
    "    unit_direction = unit_vector(frame_rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    img = (Color(1.0, 1.0, 1.0) * (1 - t) + Color(0.5, 0.7, 1.0) * t).multiply(frame_intensity)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.5 A Scene with Metal Spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "material_ground = Lambertian(Color(0.8, 0.8, 0.0))\n",
    "material_center = Lambertian(Color(0.7, 0.3, 0.3))\n",
    "material_left   = Metal(Color(0.8, 0.8, 0.8))\n",
    "material_right  = Metal(Color(0.8, 0.6, 0.2))\n",
    "\n",
    "world = [\n",
    "    Sphere(Point3( 0.0, -100.5, -1.0), 100.0, material_ground),\n",
    "    Sphere(Point3( 0.0,    0.0, -1.0),   0.5, material_center),\n",
    "    Sphere(Point3(-1.0,    0.0, -1.0),   0.5, material_left),\n",
    "    Sphere(Point3( 1.0,    0.0, -1.0),   0.5, material_right),\n",
    "]\n",
    "\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.6 Fuzzy Reflection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Metal(Material):\n",
    "\n",
    "    def __init__(self, albedo: Color, f):\n",
    "        self.albedo = albedo\n",
    "        self.fuzz = f if f < 1 else 1\n",
    "        \n",
    "    def scatter(self, r_in: Ray, rec: HitRecord) -> ScatterResult:\n",
    "\n",
    "        reflected = reflect(unit_vector(r_in.direction), rec.normal)\n",
    "        scattered = Ray(rec.p, reflected + random_in_unit_sphere(len(r_in))*self.fuzz)\n",
    "\n",
    "        return ScatterResult(attenuation = self.albedo,\n",
    "                             rays = scattered,\n",
    "                             is_scattered = dot(scattered.direction, rec.normal) > 0)    \n",
    "\n",
    "material_left   = Metal(Color(0.8, 0.8, 0.8), 0.3)\n",
    "material_right  = Metal(Color(0.8, 0.6, 0.2), 1.0)\n",
    "\n",
    "world = [\n",
    "    Sphere(Point3( 0.0, -100.5, -1.0), 100.0, material_ground),\n",
    "    Sphere(Point3( 0.0,    0.0, -1.0),   0.5, material_center),\n",
    "    Sphere(Point3(-1.0,    0.0, -1.0),   0.5, material_left),\n",
    "    Sphere(Point3( 1.0,    0.0, -1.0),   0.5, material_right),\n",
    "]\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Dielectrics\n",
    "Here we calculate both reflection and refraction for all rays. It's inefficient but easier to write, and profiling shows that we are spending little time in this function anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def refract(uv, n, etai_over_etat):\n",
    "    \n",
    "    cos_theta = dot(-uv, n)\n",
    "    r_out_perp = (uv + n*cos_theta) * etai_over_etat\n",
    "    r_out_parallel = n * (-np.sqrt(np.abs(1.0 - length_squared(r_out_perp))))\n",
    "    return r_out_perp + r_out_parallel\n",
    "\n",
    "def schlick(cosine, ref_idx):\n",
    "    r0 = (1 - ref_idx) / (1 + ref_idx)\n",
    "    r0 = r0 * r0\n",
    "    return r0 + (1 - r0) * (1 - cosine)**5\n",
    "\n",
    "\n",
    "class Dielectric(Material):\n",
    "    \n",
    "    def __init__(self, ref_idx):\n",
    "        self.ref_idx = ref_idx\n",
    "\n",
    "    def scatter(self, r_in: Ray, rec: HitRecord) -> ScatterResult:\n",
    "        \n",
    "        etai_over_etat = np.where(rec.front_face, 1.0 / self.ref_idx, self.ref_idx)\n",
    "        \n",
    "        unit_direction = unit_vector(r_in.direction)\n",
    "        \n",
    "        ## Reflection/refraction choice: calculate both and choose later\n",
    "        cos_theta = np.fmin(dot(-unit_direction, rec.normal), 1.0)\n",
    "        sin_theta = np.sqrt(1.0 - cos_theta*cos_theta)\n",
    "        reflected = reflect(unit_direction, rec.normal)\n",
    "        refracted = refract(unit_direction, rec.normal, etai_over_etat)\n",
    "\n",
    "        reflected_rays = Ray(rec.p, reflected)\n",
    "        refracted_rays = Ray(rec.p, refracted)\n",
    "\n",
    "        reflect_prob = schlick(cos_theta, etai_over_etat)\n",
    "        random_floats = my_random(0.0, 1.0, len(reflect_prob))\n",
    "\n",
    "        must_reflect = (etai_over_etat * sin_theta > 1.0)\n",
    "        again_reflect = (random_floats < reflect_prob)\n",
    "\n",
    "        all_reflect = np.where(np.logical_or(must_reflect, again_reflect))\n",
    "        \n",
    "        refracted_rays[all_reflect] = reflected_rays[all_reflect]\n",
    "        \n",
    "        return ScatterResult(attenuation = Color(1.0, 1.0, 1.0),\n",
    "                             rays = refracted_rays,\n",
    "                             is_scattered = np.full(len(r_in), True, dtype=bool))\n",
    "\n",
    "\n",
    "material_ground = Lambertian(Color(0.8, 0.8, 0.0))\n",
    "material_center = Lambertian(Color(0.1, 0.2, 0.5));\n",
    "material_left   = Dielectric(1.5)\n",
    "material_right  = Metal(Color(0.8, 0.6, 0.2), 0.0)\n",
    "\n",
    "world = [\n",
    "    Sphere(Point3( 0.0, -100.5, -1.0), 100.0, material_ground),\n",
    "    Sphere(Point3( 0.0,    0.0, -1.0),   0.5, material_center),\n",
    "    Sphere(Point3(-1.0,    0.0, -1.0),   0.5, material_left),\n",
    "    Sphere(Point3(-1.0,    0.0, -1.0),  -0.4, material_left),\n",
    "    Sphere(Point3( 1.0,    0.0, -1.0),   0.5, material_right),\n",
    "]\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Positionable Camera\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following chapter 12.1 of the book to setup a Camera vertical field of view and aspect ratio. We also add a function to move the camera around. \n",
    "We test these new features by rendering a scene with a camera that is not at the origin and a simnple scene with a single of two touching spheres using a 90 degree vertical field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Camera:\n",
    "\n",
    "    def __init__(self, vfov,           # vertical field-of-view in degrees\n",
    "                       aspect_ratio):\n",
    "\n",
    "        theta = np.deg2rad(vfov)\n",
    "        h = np.tan(theta/2)\n",
    "        viewport_height = 2.0 * h;\n",
    "        viewport_width = aspect_ratio * viewport_height;\n",
    "        focal_length = 1.0;\n",
    "\n",
    "        self.origin = Point3(0, 0, 0);\n",
    "        self.horizontal = Vec3(viewport_width, 0.0, 0.0);\n",
    "        self.vertical = Vec3(0.0, -viewport_height, 0.0);\n",
    "        self.lower_left_corner = (self.origin\n",
    "                                    - self.horizontal/2\n",
    "                                    - self.vertical/2\n",
    "                                    - Vec3(0, 0, focal_length))\n",
    "\n",
    "    def get_ray(self, u, v):\n",
    "        all_origins = origin.tile((u.size,))\n",
    "        return Ray(all_origins, self.lower_left_corner\n",
    "                                + self.horizontal * u\n",
    "                                + self.vertical * v\n",
    "                                - all_origins)\n",
    "\n",
    "R = np.cos(np.pi/4);\n",
    "\n",
    "material_left   = Lambertian(Color(0, 0, 1))\n",
    "material_right  = Lambertian(Color(1, 0, 0))\n",
    "\n",
    "world = [\n",
    "    Sphere(Point3(-R, 0, -1), R, material_left),\n",
    "    Sphere(Point3( R, 0, -1), R, material_right),\n",
    "]\n",
    "\n",
    "\n",
    "def get_camera():\n",
    "    return Camera(90.0, aspect_ratio)\n",
    "\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add `lookat`, `lookfrom` and `vup`points and vectors to the Camera class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Camera:\n",
    "\n",
    "    def __init__(self, lookfrom,\n",
    "                       lookat,\n",
    "                       vup,\n",
    "                       vfov,           # vertical field-of-view in degrees\n",
    "                       aspect_ratio):\n",
    "\n",
    "        theta = np.deg2rad(vfov)\n",
    "        h = np.tan(theta/2)\n",
    "        viewport_height = 2.0 * h;\n",
    "        viewport_width = aspect_ratio * viewport_height;\n",
    "\n",
    "        w = unit_vector(lookfrom - lookat)\n",
    "        u = cross(vup, w)\n",
    "        v = -cross(w, u)           # Minus here, to have things looking upright\n",
    "\n",
    "        self.origin = lookfrom\n",
    "        self.horizontal = u * viewport_width\n",
    "        self.vertical = v * viewport_height\n",
    "        self.lower_left_corner = self.origin - self.horizontal/2 - self.vertical/2 - w\n",
    "\n",
    "    def get_ray(self, s, t):\n",
    "        all_origins = self.origin.tile((s.size,))\n",
    "        return Ray(all_origins, self.lower_left_corner\n",
    "                                + self.horizontal * s\n",
    "                                + self.vertical * t\n",
    "                                - all_origins)\n",
    "\n",
    "\n",
    "\n",
    "def get_camera():\n",
    "    return Camera(lookfrom = Point3(0,0,0),\n",
    "                  lookat   = Point3(0,0,-1),\n",
    "                  vup      = Vec3(0,1,0),\n",
    "                  vfov     = 90,\n",
    "                  aspect_ratio = aspect_ratio)\n",
    "\n",
    "material_ground = Lambertian(Color(0.8, 0.8, 0.0))\n",
    "material_center = Lambertian(Color(0.1, 0.2, 0.5));\n",
    "material_left   = Dielectric(1.5)\n",
    "material_right  = Metal(Color(0.8, 0.6, 0.2), 0.0)\n",
    "\n",
    "world = [\n",
    "    Sphere(Point3( 0.0, -100.5, -1.0), 100.0, material_ground),\n",
    "    Sphere(Point3( 0.0,    0.0, -1.0),   0.5, material_center),\n",
    "    Sphere(Point3(-1.0,    0.0, -1.0),   0.5, material_left),\n",
    "    Sphere(Point3(-1.0,    0.0, -1.0),  -0.45, material_left),\n",
    "    Sphere(Point3( 1.0,    0.0, -1.0),   0.5, material_right),\n",
    "]\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use another viewpoint for the two spheres scene, and add a ground plane to the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera():\n",
    "    return Camera(lookfrom = Point3(-2,2,1),\n",
    "                  lookat   = Point3(0,0,-1),\n",
    "                  vup      = Vec3(0,1,0),\n",
    "                  vfov      = 90,\n",
    "                  aspect_ratio = aspect_ratio)\n",
    "\n",
    "display(render(width, height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and also change the vofv to 20:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_camera():\n",
    "    return Camera(lookfrom = Point3(-2,2,1),\n",
    "                  lookat   = Point3(0,0,-1),\n",
    "                  vup      = Vec3(0,1,0),\n",
    "                  vfov      = 20,\n",
    "                  aspect_ratio = aspect_ratio)\n",
    "\n",
    "display(render(width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Defocus Blur\n",
    "Adding the thin lens approximation to the camera, and a defocus blur to the render_image function according to chapter 13 of the book to render spheres with depth-of-field blur cinematic effects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_in_unit_disk(n):\n",
    "    ''''Generate random Vec3 arrays in batches and keep the ones inside the unit disk'''\n",
    "\n",
    "    values = Vec3.zeros(0)\n",
    "\n",
    "    while len(values) < n:\n",
    "        random_values = Vec3(my_random(-1.0, 1.0, n), my_random(-1.0, 1.0, n), np.zeros(n))\n",
    "        good_ones = length_squared(random_values) < 1\n",
    "        values.append(random_values[good_ones])\n",
    "    \n",
    "    return values[:n]\n",
    "\n",
    "\n",
    "class Camera:\n",
    "\n",
    "    def __init__(self, lookfrom: Vec3,\n",
    "                       lookat: Vec3,\n",
    "                       vup: Vec3,\n",
    "                       vfov: float,           # vertical field-of-view in degrees\n",
    "                       aspect_ratio: float,\n",
    "                       aperture: float,\n",
    "                       focus_dist: float):\n",
    "\n",
    "        theta = np.deg2rad(vfov)\n",
    "        h = np.tan(theta/2)\n",
    "        viewport_height = 2.0 * h;\n",
    "        viewport_width = aspect_ratio * viewport_height;\n",
    "\n",
    "        w = unit_vector(lookfrom - lookat)\n",
    "        u = cross(vup, w)\n",
    "        v = -cross(w, u)           # Minus here, to have things looking upright\n",
    "\n",
    "        self.origin = lookfrom\n",
    "        self.horizontal = u * viewport_width * focus_dist\n",
    "        self.vertical = v * viewport_height * focus_dist\n",
    "        self.lower_left_corner = self.origin - self.horizontal/2 - self.vertical/2 - w*focus_dist\n",
    "        self.lens_radius = aperture / 2\n",
    "        self.u = u\n",
    "        self.v = v\n",
    "\n",
    "    def get_ray(self, s, t):\n",
    "        all_origins = self.origin.tile((s.size,))\n",
    "        rd = random_in_unit_disk(s.size) * self.lens_radius\n",
    "        offset = self.u * rd.x + self.v * rd.y\n",
    "\n",
    "        return Ray(all_origins + offset, self.lower_left_corner\n",
    "                                         + self.horizontal * s\n",
    "                                         + self.vertical * t\n",
    "                                         - all_origins - offset)\n",
    "    \n",
    "def get_camera():\n",
    "    lookfrom = Point3(3,3,2)\n",
    "    lookat = Point3(0,0,-1)\n",
    "    \n",
    "    return Camera(lookfrom = lookfrom,\n",
    "                  lookat   = lookat,\n",
    "                  vup      = Vec3(0,1,0),\n",
    "                  vfov     = 20,\n",
    "                  aspect_ratio = 16/9,\n",
    "                  aperture = 2.0,\n",
    "                  focus_dist = length(lookfrom-lookat))\n",
    "\n",
    "display(render(width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Final render\n",
    "This cell is set to \"Markdown\" instead of \"Code\", because it takes up to several minutes to run and it could slow-down/hang your notebook.\n",
    "\n",
    "It generates a scene with 3 large spheres, 20 random spheres and a ground plane, and renders it with a defocus blur. The scene is illuminated by a single point light source. The camera is positioned at a slight angle to the scene, and the vertical field of view is set to 20 degrees. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def random_double(low=0.0, high=1.0):\n",
    "    return np.random.uniform(low, high, 1).astype(np.float32)\n",
    "\n",
    "def vec3_random(low=0.0, high=1.0):\n",
    "    r = my_random(low, high, size=3)\n",
    "    return Vec3(r[0], r[1], r[2])\n",
    "\n",
    "\n",
    "ground_material = Lambertian(Color(0.5, 0.5, 0.5))\n",
    "\n",
    "world = []\n",
    "world.append(Sphere(Point3(0, -1000, 0), 1000, ground_material))\n",
    "\n",
    "for a in range(-11, 11):\n",
    "    for b in range(-11, 11):\n",
    "        choose_mat = random_double()\n",
    "        center = Point3(a + 0.9*random_double(), 0.2, b + 0.9*random_double())\n",
    "\n",
    "        if length(center - Point3(4, 0.2, 0)) > 0.9:\n",
    "\n",
    "            if choose_mat < 0.8:\n",
    "                ## diffuse\n",
    "                albedo = vec3_random().multiply(vec3_random())\n",
    "                sphere_material = Lambertian(albedo)\n",
    "                world.append(Sphere(center, 0.2, sphere_material))\n",
    "\n",
    "            elif choose_mat < 0.95:\n",
    "                ## metal\n",
    "                albedo = vec3_random(0.5, 1)\n",
    "                fuzz = random_double(0, 0.5)\n",
    "                sphere_material = Metal(albedo, fuzz)\n",
    "                world.append(Sphere(center, 0.2, sphere_material))\n",
    "\n",
    "            else:\n",
    "                ## glass\n",
    "                sphere_material = Dielectric(1.5)\n",
    "                world.append(Sphere(center, 0.2, sphere_material))\n",
    "\n",
    "\n",
    "world.append(Sphere(Point3( 0, 1, 0), 1.0, Dielectric(1.5)))\n",
    "world.append(Sphere(Point3(-4, 1, 0), 1.0, Lambertian(Color(0.4, 0.2, 0.1))))\n",
    "world.append(Sphere(Point3( 4, 1, 0), 1.0, Metal(Color(0.7, 0.6, 0.5), 0.0)))\n",
    "\n",
    "image_width = 1000\n",
    "aspect_ratio = 3/2\n",
    "image_height = int(image_width / aspect_ratio)\n",
    "samples_per_pixel = 3 #  For a realistic image you need to set this to 500\n",
    "max_depth = 50\n",
    "\n",
    "def get_camera():\n",
    "    lookfrom = Point3(13,2,3)\n",
    "    lookat = Point3(0,0,0)\n",
    "    \n",
    "    return Camera(lookfrom = lookfrom,\n",
    "                  lookat   = lookat,\n",
    "                  vup      = Vec3(0,1,0),\n",
    "                  vfov     = 20,\n",
    "                  aspect_ratio = aspect_ratio,\n",
    "                  aperture     = 0.1,\n",
    "                  focus_dist   = 10.0)\n",
    "\n",
    "display(render(image_width, image_height))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### here it is below if you want to try it out ;-)\n",
    "#### (**39secs** on Apple silicon M1 Max with 3 samples per pixel):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_double(low=0.0, high=1.0):\n",
    "    return np.random.uniform(low, high, 1).astype(np.float32)\n",
    "\n",
    "def vec3_random(low=0.0, high=1.0):\n",
    "    r = my_random(low, high, size=3)\n",
    "    return Vec3(r[0], r[1], r[2])\n",
    "\n",
    "\n",
    "ground_material = Lambertian(Color(0.5, 0.5, 0.5))\n",
    "\n",
    "world = []\n",
    "world.append(Sphere(Point3(0, -1000, 0), 1000, ground_material))\n",
    "\n",
    "for a in range(-11, 11):\n",
    "    for b in range(-11, 11):\n",
    "        choose_mat = random_double()\n",
    "        center = Point3(a + 0.9*random_double(), 0.2, b + 0.9*random_double())\n",
    "\n",
    "        if length(center - Point3(4, 0.2, 0)) > 0.9:\n",
    "\n",
    "            if choose_mat < 0.8:\n",
    "                ## diffuse\n",
    "                albedo = vec3_random().multiply(vec3_random())\n",
    "                sphere_material = Lambertian(albedo)\n",
    "                world.append(Sphere(center, 0.2, sphere_material))\n",
    "\n",
    "            elif choose_mat < 0.95:\n",
    "                ## metal\n",
    "                albedo = vec3_random(0.5, 1)\n",
    "                fuzz = random_double(0, 0.5)\n",
    "                sphere_material = Metal(albedo, fuzz)\n",
    "                world.append(Sphere(center, 0.2, sphere_material))\n",
    "\n",
    "            else:\n",
    "                ## glass\n",
    "                sphere_material = Dielectric(1.5)\n",
    "                world.append(Sphere(center, 0.2, sphere_material))\n",
    "\n",
    "\n",
    "world.append(Sphere(Point3( 0, 1, 0), 1.0, Dielectric(1.5)))\n",
    "world.append(Sphere(Point3(-4, 1, 0), 1.0, Lambertian(Color(0.4, 0.2, 0.1))))\n",
    "world.append(Sphere(Point3( 4, 1, 0), 1.0, Metal(Color(0.7, 0.6, 0.5), 0.0)))\n",
    "\n",
    "image_width = 1000\n",
    "aspect_ratio = 3/2\n",
    "image_height = int(image_width / aspect_ratio)\n",
    "samples_per_pixel = 3 #  For a realistic image you need to set this to 500 (42sec in apple silicon M1max)\n",
    "#samples_per_pixel = 500 #  this might take some time to render (3100 sec in apple silicon M1max)\n",
    "max_depth = 50\n",
    "\n",
    "def get_camera():\n",
    "    lookfrom = Point3(13,2,3)\n",
    "    lookat = Point3(0,0,0)\n",
    "    \n",
    "    return Camera(lookfrom = lookfrom,\n",
    "                  lookat   = lookat,\n",
    "                  vup      = Vec3(0,1,0),\n",
    "                  vfov     = 20,\n",
    "                  aspect_ratio = aspect_ratio,\n",
    "                  aperture     = 0.1,\n",
    "                  focus_dist   = 10.0)\n",
    "\n",
    "display(render(image_width, image_height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Python Optimizations\n",
    "Our render works, but is very slow. We'll try to make it faster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### length_squared()\n",
    "One of the heaviest used functions is length_squared(). We'll cache the most common usage, before calling update_hit_record(), using the property decorator. This optimization alone makes the overall render about 10% faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ray:\n",
    "    def __init__(self, origin, direction):\n",
    "        self.origin = origin\n",
    "        self.direction = direction\n",
    "        self._direction_length_squared = None\n",
    "\n",
    "    def at(self, t):\n",
    "        return self.origin + self.direction*t\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return Ray(self.origin[idx], self.direction[idx])\n",
    "\n",
    "    def __setitem__(self, idx, other):\n",
    "        self.origin[idx] = other.origin\n",
    "        self.direction[idx] = other.direction\n",
    "        self._direction_length_squared = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.origin.x.size\n",
    "    \n",
    "    def direction_length_squared(self):\n",
    "        if self._direction_length_squared is None:\n",
    "            self._direction_length_squared = length_squared(self.direction)\n",
    "        return self._direction_length_squared\n",
    "\n",
    "\n",
    "class Sphere(Hittable):\n",
    "    '''A hittable sphere that knows how to update the hit record'''\n",
    "\n",
    "    def __init__(self, center, radius, material):\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "        self.material = material\n",
    "\n",
    "    def update_hit_record(self, rays, t_min, t_max, hit_record):\n",
    "\n",
    "        oc = rays.origin - self.center\n",
    "        a = rays.direction_length_squared()                    # Changed here\n",
    "        half_b = dot(oc, rays.direction)\n",
    "        c = length_squared(oc) - self.radius*self.radius\n",
    "        discriminant = half_b*half_b - a*c\n",
    "        \n",
    "        root = np.sqrt(discriminant)\n",
    "        t1 = (-half_b - root) / a\n",
    "        t2 = (-half_b + root) / a\n",
    "        hit1 = np.logical_and(t1 < t_max, t1 > t_min)\n",
    "        hit2 = np.logical_and(t2 < t_max, t2 > t_min)\n",
    "        \n",
    "        # Combine the two hits, precedence to t1 (closest)\n",
    "        t = np.where(hit2, t2, np.inf)\n",
    "        t = np.where(hit1, t1, t)       \n",
    "        \n",
    "        # Detect where in the rays list we are the closest hit\n",
    "        closest = np.where(t < hit_record.t)\n",
    "        \n",
    "        # Early exit if nothing hit\n",
    "        if len(closest[0]) == 0:\n",
    "            return\n",
    "        \n",
    "        # Calculate normal\n",
    "        hit_rays = rays[closest]\n",
    "        \n",
    "        p = hit_rays.at(t[closest])\n",
    "        outward_normal = (p - self.center) / self.radius \n",
    "        front_face = dot(hit_rays.direction, outward_normal) < 0 \n",
    "        normal = Vec3.where(front_face, outward_normal, -outward_normal)\n",
    "        \n",
    "        # Update hit record\n",
    "        hit_record.p[closest] = p\n",
    "        hit_record.normal[closest] = normal\n",
    "        hit_record.t[closest] = t[closest]\n",
    "        hit_record.front_face[closest] = front_face\n",
    "        hit_record.material_id[closest] = id(self.material)\n",
    "\n",
    "image_width = 400\n",
    "aspect_ratio = 16/9\n",
    "image_height = int(image_width / aspect_ratio)\n",
    "samples_per_pixel = 3\n",
    "max_depth = 50\n",
    "\n",
    "def get_camera():\n",
    "    lookfrom = Point3(3,3,2)\n",
    "    lookat = Point3(0,0,-1)\n",
    "    \n",
    "    return Camera(lookfrom = lookfrom,\n",
    "                  lookat   = lookat,\n",
    "                  vup      = Vec3(0,1,0),\n",
    "                  vfov     = 20,\n",
    "                  aspect_ratio = 16/9,\n",
    "                  aperture = 2.0,\n",
    "                  focus_dist = length(lookfrom-lookat))\n",
    "\n",
    "display(render(image_width, image_height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### np.array()\n",
    "The np.array() calls in the Vec3 initializers are almost always useless, because most of the time the arguments are already arrays. Removing these calls will gain another 10%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vec3:\n",
    "    def __init__(self, x=0.0, y=0.0, z=0.0):\n",
    "        self.x = x if type(x) == np.ndarray else np.array(x, dtype=np.float32)\n",
    "        self.y = y if type(y) == np.ndarray else np.array(y, dtype=np.float32)\n",
    "        self.z = z if type(z) == np.ndarray else np.array(z, dtype=np.float32)\n",
    "\n",
    "    @staticmethod\n",
    "    def empty(size):\n",
    "        x = np.empty(size, dtype=np.float32)\n",
    "        y = np.empty(size, dtype=np.float32)\n",
    "        z = np.empty(size, dtype=np.float32)\n",
    "        return Vec3(x,y,z)\n",
    "\n",
    "    @staticmethod\n",
    "    def zeros(size):\n",
    "        x = np.zeros(size, dtype=np.float32)\n",
    "        y = np.zeros(size, dtype=np.float32)\n",
    "        z = np.zeros(size, dtype=np.float32)\n",
    "        return Vec3(x,y,z)\n",
    "\n",
    "    @staticmethod\n",
    "    def ones(size):\n",
    "        x = np.ones(size, dtype=np.float32)\n",
    "        y = np.ones(size, dtype=np.float32)\n",
    "        z = np.ones(size, dtype=np.float32)\n",
    "        return Vec3(x,y,z)\n",
    "    \n",
    "    @staticmethod\n",
    "    def where(condition, v1, v2):\n",
    "        x = np.where(condition, v1.x, v2.x)\n",
    "        y = np.where(condition, v1.y, v2.y)\n",
    "        z = np.where(condition, v1.z, v2.z)\n",
    "        return Vec3(x,y,z)\n",
    "    \n",
    "    def clip(self, vmin, vmax):\n",
    "        x = np.clip(self.x, vmin, vmax)\n",
    "        y = np.clip(self.y, vmin, vmax)\n",
    "        z = np.clip(self.z, vmin, vmax)\n",
    "        return Vec3(x,y,z)\n",
    "\n",
    "    def fill(self, value):\n",
    "        self.x.fill(value)\n",
    "        self.y.fill(value)\n",
    "        self.z.fill(value)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return 'vec3: x:%s y:%s z:%s' % (str(self.x), str(self.y), str(self.z))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.size\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Vec3(self.x + other.x, self.y + other.y, self.z + other.z)\n",
    "\n",
    "    def __sub__(self, other):\n",
    "        return Vec3(self.x - other.x, self.y - other.y, self.z - other.z)\n",
    "\n",
    "    def __neg__(self):\n",
    "        return Vec3(-self.x, -self.y, -self.z)\n",
    "\n",
    "    def __mul__(self, scalar):\n",
    "        return Vec3(self.x*scalar, self.y*scalar, self.z*scalar)\n",
    "\n",
    "    def multiply(self, other):\n",
    "        return Vec3(self.x * other.x, self.y * other.y, self.z * other.z)\n",
    "\n",
    "    def __truediv__(self, scalar):\n",
    "        return Vec3(self.x/scalar, self.y/scalar, self.z/scalar)\n",
    "    \n",
    "    def tile(self, shape):\n",
    "        '''Replicate np.tile on each component'''\n",
    "        return Vec3(np.tile(self.x, shape), np.tile(self.y, shape), np.tile(self.z, shape))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        '''Extract a vector subset'''\n",
    "        return Vec3(self.x[idx], self.y[idx], self.z[idx])\n",
    "    \n",
    "    def __setitem__(self, idx, other):\n",
    "        '''Set a vector subset from another vector'''\n",
    "        self.x[idx] = other.x\n",
    "        self.y[idx] = other.y\n",
    "        self.z[idx] = other.z\n",
    "\n",
    "    def join(self):\n",
    "        '''Join the three components into a single 3xN array'''\n",
    "        return np.vstack((self.x, self.y, self.z))\n",
    "    \n",
    "    def append(self, other):\n",
    "        '''Append another vector to this one.\n",
    "        Use concatenate() because cupy has no append function.\n",
    "        '''\n",
    "        self.x = np.concatenate((self.x, other.x))\n",
    "        self.y = np.concatenate((self.y, other.y))\n",
    "        self.z = np.concatenate((self.z, other.z))\n",
    "        \n",
    "display(render(image_width, image_height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smarter hit record\n",
    "When we have lots of objects in our world (like it the final render, almost 500 spheres), the hit record fields are going to be overwritten many times as closer and closer hits are found. We can split *update_hit_record()* in two parts, one to look for the closest sphere, and the other to calculate the normals.\n",
    "\n",
    "We will also take advantage of the fact that our t_max is always infinite, so there is no real need to check against it, and optimize the *t* comparison.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HitRecord:\n",
    "    def __init__(self, n, empty=False):\n",
    "        self.p           = empty or Vec3.empty(n)\n",
    "        self.normal      = empty or Vec3.empty(n)\n",
    "        self.front_face  = empty or np.empty(n, dtype=bool)\n",
    "        self.t           = empty or np.full(n, np.inf, dtype=np.float32)\n",
    "        self.center      = empty or Vec3.empty(n)\n",
    "        self.radius      = empty or np.empty(n, dtype=np.float32)\n",
    "        self.index       = empty or np.arange(n, dtype=np.int32)\n",
    "        self.material_id = empty or np.zeros(n, dtype=np.int64)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        other = HitRecord(len(idx), empty=True)\n",
    "        other.p           = self.p[idx]\n",
    "        other.normal      = self.normal[idx]\n",
    "        other.front_face = self.front_face[idx]\n",
    "        other.t           = self.t[idx]\n",
    "        other.center      = self.center[idx]\n",
    "        other.radius      = self.radius[idx]\n",
    "        other.index       = self.index[idx]\n",
    "        other.material_id = self.material_id[idx]\n",
    "        return other\n",
    "\n",
    "    \n",
    "class Sphere(Hittable):\n",
    "    '''A hittable sphere that knows how to update the hit record'''\n",
    "\n",
    "    def __init__(self, center, radius, material):\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "        self.material = material \n",
    "\n",
    "    def update_hit_record(self, rays, t_min, t_max, hit_record):\n",
    "        \n",
    "        oc = rays.origin - self.center\n",
    "        a = rays.direction_length_squared()\n",
    "        half_b = dot(oc, rays.direction)\n",
    "        c = length_squared(oc) - self.radius*self.radius\n",
    "        discriminant = half_b*half_b - a*c\n",
    "        \n",
    "        hits = np.where(discriminant >= 0)[0]\n",
    "\n",
    "        # Early exit if our rays did not hit the sphere at all\n",
    "        if len(hits) == 0:\n",
    "            return\n",
    "\n",
    "        # Only calculate roots on those rays that have hit\n",
    "        half_b = half_b[hits]\n",
    "        a = a[hits]\n",
    "        \n",
    "        root = np.sqrt(discriminant[hits])\n",
    "        t1 = (-half_b - root) / a\n",
    "        t2 = (-half_b + root) / a\n",
    "        \n",
    "        # Update hit record where we are the closest\n",
    "        t = np.where(t1 > t_min, t1, t2)\n",
    "        closest = np.where((t < hit_record.t[hits]) & (t > t_min))\n",
    "        \n",
    "        idx = hits[closest]\n",
    "        hit_record.t[idx] = t[closest]\n",
    "        hit_record.center[idx] = self.center\n",
    "        hit_record.radius[idx] = self.radius\n",
    "        hit_record.material_id[idx] = id(self.material)\n",
    "\n",
    "\n",
    "def calculate_normals(rays, hit_record):\n",
    "\n",
    "    p = rays.at(hit_record.t)\n",
    "    outward_normal = (p - hit_record.center) / hit_record.radius \n",
    "    front_face = dot(rays.direction, outward_normal) < 0 \n",
    "    normal = Vec3.where(front_face, outward_normal, -outward_normal)\n",
    "    \n",
    "    return p, normal, front_face\n",
    "\n",
    "\n",
    "def ray_color(rays):\n",
    "    '''Iterative version with materials'''\n",
    "\n",
    "    intensity = Vec3.ones(len(rays))\n",
    "    all_rays = rays\n",
    "    hit_record = HitRecord(len(rays))\n",
    "\n",
    "    materials = set([x.material for x in world])\n",
    "\n",
    "    for d in range(max_depth):\n",
    "\n",
    "        # Initialize all distances to infinite and propagate all rays\n",
    "        hit_record.t.fill(np.inf)\n",
    "        hit_record.material_id.fill(0)\n",
    "        \n",
    "        for hittable in world:\n",
    "            hittable.update_hit_record(rays, 0.001, np.inf, hit_record)         \n",
    "        \n",
    "        # Calculate all hits normal and build a hit record for the scattering\n",
    "        hits = np.where(hit_record.t != np.inf)[0]\n",
    "        p, normal, front_face = calculate_normals(rays[hits], hit_record[hits])\n",
    "        \n",
    "        material_rays = rays[hits]\n",
    "        material_hit_record = hit_record[hits]\n",
    "        material_hit_record.p = p\n",
    "        material_hit_record.normal = normal\n",
    "        material_hit_record.front_face = front_face\n",
    "        \n",
    "        for material in materials:\n",
    "\n",
    "            material_hits = np.where(material_hit_record.material_id == id(material))[0]\n",
    "            if len(material_hits) == 0:\n",
    "                continue\n",
    "\n",
    "            # Narrow down to this material and scatter\n",
    "            my_rays = material_rays[material_hits]\n",
    "            my_rec = material_hit_record[material_hits]\n",
    "            result = material.scatter(my_rays, my_rec)         \n",
    "            \n",
    "            # All rays have done something\n",
    "            all_rays[my_rec.index] = result.rays\n",
    "            \n",
    "            # Attenuation\n",
    "            this_intensity = result.attenuation.multiply(intensity[my_rec.index])\n",
    "            this_intensity[np.where(~result.is_scattered)] = Vec3(0,0,0)\n",
    "            intensity[my_rec.index] = this_intensity\n",
    "\n",
    "            # Those that have been scattered stop here\n",
    "            not_scattered_material_idx = hits[material_hits[~result.is_scattered]]\n",
    "            hit_record.t[not_scattered_material_idx] = np.inf\n",
    "            \n",
    "        # Iterate with those rays that have been scattered by something\n",
    "        scattered_rays = np.where(hit_record.t != np.inf)[0]\n",
    "\n",
    "        hit_record = hit_record[scattered_rays]\n",
    "        rays = all_rays[hit_record.index]\n",
    "\n",
    "        if len(rays) == 0:\n",
    "            break\n",
    "            \n",
    "    unit_direction = unit_vector(all_rays.direction)\n",
    "    t = 0.5 * unit_direction.y + 1.0\n",
    "    img = (Color(1.0, 1.0, 1.0) * (1 - t) + Color(0.5, 0.7, 1.0) * t).multiply(intensity)\n",
    "\n",
    "    return img\n",
    "\n",
    "world = [\n",
    "    Sphere(Point3( 0.0, -100.5, -1.0), 100.0, material_ground),\n",
    "    Sphere(Point3( 0.0,    0.0, -1.0),   0.5, material_center),\n",
    "    Sphere(Point3(-1.0,    0.0, -1.0),   0.5, material_left),\n",
    "    Sphere(Point3(-1.0,    0.0, -1.0),  -0.45, material_left),\n",
    "    Sphere(Point3( 1.0,    0.0, -1.0),   0.5, material_right),\n",
    "]\n",
    "\n",
    "display(render(image_width, image_height))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Multiprocessing\n",
    "First we split the rendering function for a single sample into its own function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def img_for_sample(s, cam, u, v, width, height):\n",
    "    \n",
    "    uu = u + my_random(0.0, 1.0, u.size) / (width - 1)\n",
    "    vv = v + my_random(0.0, 1.0, v.size) / (height - 1)\n",
    "\n",
    "    rays = cam.get_ray(uu,vv)\n",
    "\n",
    "    return ray_color(rays)    \n",
    "    \n",
    "    \n",
    "def render_image(width, height):\n",
    "    with Timer():\n",
    "        ii, jj = np.mgrid[:float(height), :float(width)]\n",
    "\n",
    "        u = (jj/(width-1)).flatten().astype(np.float32)\n",
    "        v = (ii/(height-1)).flatten().astype(np.float32)\n",
    "\n",
    "        cam = get_camera()\n",
    "\n",
    "        img = Vec3.zeros(width * height)\n",
    "        for s in range(samples_per_pixel):\n",
    "            \n",
    "            print(s)\n",
    "            img += img_for_sample(s, cam, u, v, width, height)\n",
    "            \n",
    "        img *= 1.0 / samples_per_pixel\n",
    "        img.x = np.sqrt(img.x)\n",
    "        img.y = np.sqrt(img.y)\n",
    "        img.z = np.sqrt(img.z)\n",
    "        return img.clip(0.0, 0.999)\n",
    "\n",
    "\n",
    "display(render(width, height))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we call it from a multiprocessing.Pool. It does not work on the notebook, because jupyter gets confused by our multiple class redefinitions in the previous notebook cells. Therefore the following cell is not marked as actual code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import multiprocessing as mp\n",
    "from functools import partial, reduce\n",
    "\n",
    "def render_image(width, height):\n",
    "    with Timer():\n",
    "        ii, jj = np.mgrid[:float(height), :float(width)]\n",
    "\n",
    "        u = (jj/(width-1)).flatten().astype(np.float32)\n",
    "        v = (ii/(height-1)).flatten().astype(np.float32)\n",
    "\n",
    "        cam = get_camera()1\n",
    "\n",
    "        img = Vec3.zeros(width * height)\n",
    "        myfunc = partial(img_for_sample, cam=cam, u=u, v=v, width=width, height=height)\n",
    "        \n",
    "        with mp.Pool() as p:\n",
    "            samples = p.map(myfunc, range(samples_per_pixel))\n",
    "           \n",
    "        img = sum(samples)\n",
    "        img *= 1.0 / samples_per_pixel\n",
    "        img.x = np.sqrt(img.x)\n",
    "        img.y = np.sqrt(img.y)\n",
    "        img.z = np.sqrt(img.z)\n",
    "        return img.clip(0.0, 0.999)\n",
    "\n",
    "display(render(width, height))\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elementsProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
